{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "Import required libraries including NumPy, sklearn with Intel extension, and pi_optimal utilities. Configure warning suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment and Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "#from sklearnex import patch_sklearn\n",
    "import warnings\n",
    "\n",
    "# Change directory to the parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Apply Intel extension to sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import pi_optimal utilities\n",
    "from pi_optimal.utils.data_generators.gym_data_generator import GymDataGenerator\n",
    "from pi_optimal.datasets.timeseries_dataset import TimeseriesDataset\n",
    "from pi_optimal.models.sklearn.random_forest_model import RandomForest\n",
    "from pi_optimal.models.sklearn.mlp import NeuralNetwork\n",
    "from pi_optimal.evaluators.base_evaluator import BaseEvaluator\n",
    "from pi_optimal.evaluators.plotting import plot_n_step_evaluation, plot_n_step_episode_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gym Data Generator\n",
    "Initialize GymDataGenerator with LunarLander environment and collect training and test data with specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps:   7%|‚ñã         | 736/10000 [00:00<00:01, 7358.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 10852.98it/s]\n",
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00<00:00, 13159.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create Gym Data Generator\n",
    "\n",
    "# Initialize GymDataGenerator with LunarLander environment\n",
    "data_collector = GymDataGenerator(env_name=\"LunarLander-v3\")\n",
    "\n",
    "# Collect training data\n",
    "df_train = data_collector.collect(n_steps=10000, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "df_test = data_collector.collect(n_steps=5000, max_steps_per_episode=200, env_seed=None, action_seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Dataset Parameters\n",
    "Set up dataset configuration dictionary defining features, processors, and evaluation metrics for states, actions, and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Dataset Parameters\n",
    "\n",
    "# Define dataset configuration dictionary\n",
    "dataset_config = {\n",
    "    \"episode_column\": \"episode\",\n",
    "    \"timestep_column\": \"step\",\n",
    "    \"states\": {\n",
    "        0: {\"name\": \"state_0\", \"type\": \"numerical\", \"processor\": {\"name\": \"StandardScaler\"}, \"evaluation_metric\": \"mae\"},\n",
    "        1: {\"name\": \"state_1\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        2: {\"name\": \"state_2\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        3: {\"name\": \"state_3\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        4: {\"name\": \"state_4\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        5: {\"name\": \"state_5\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        6: {\"name\": \"state_6\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        7: {\"name\": \"state_7\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        8: {\"name\": \"done\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        9: {\"name\": \"reward\", \"type\": \"numerical\", \"processor\": {\"name\": \"PowerTransformer\"}, \"evaluation_metric\": \"mae\"},\n",
    "    },\n",
    "    \"actions\": {\n",
    "        0: {\"name\": \"action_0\", \"type\": \"categorial\", \"processor\": {\"name\": \"OneHotEncoder\"}},\n",
    "    },\n",
    "    \"reward_feature_idx\": 9,\n",
    "    \"reward_vector_idx\": 9,\n",
    "    \"reward_column\": \"reward\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Test Datasets\n",
    "Initialize TimeseriesDataset objects with collected data, applying the configuration and setting lookback/forecast windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10000 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 109 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Fitting feature processors...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Processors created and fitted</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean -0.04 and std 0.31'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 5000 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 56 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Using processors provided in the dataset_configuration.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean -0.04 and std 0.31'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Training and Test Datasets\n",
    "\n",
    "# Define lookback and forecast timesteps\n",
    "LOOKBACK_TIMESTEPS = 10\n",
    "FORECAST_TIMESTEPS = 1\n",
    "\n",
    "# Initialize TimeseriesDataset objects for training and test data\n",
    "dataset_train = TimeseriesDataset(\n",
    "    df=df_train,\n",
    "    dataset_config=dataset_config,\n",
    "    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "    forecast_timesteps=FORECAST_TIMESTEPS,\n",
    "    train_processors=True\n",
    ")\n",
    "\n",
    "\n",
    "dataset_test = TimeseriesDataset(\n",
    "    df=df_test,\n",
    "    dataset_config=dataset_config,\n",
    "    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "    forecast_timesteps=FORECAST_TIMESTEPS,\n",
    "    train_processors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network Model\n",
    "Create and train a Neural Network model with specified hyperparameters on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2d604cd7604e83a12cff558dab2311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model1_params = {\n",
    "    \"hidden_layer_sizes\":(128, 128),\n",
    "    \"alpha\":0.01, \n",
    "    \"learning_rate_init\": 0.001\n",
    "    }\n",
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model1 = NeuralNetwork(nn_model1_params )\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model1.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1195d7fda1db4b23983915fbad27183b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model2_params = {\n",
    "    \"hidden_layer_sizes\":(128, 128),\n",
    "    \"alpha\":0.01, \n",
    "    \"learning_rate_init\": 0.001\n",
    "    }\n",
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model2 = NeuralNetwork(nn_model2_params)\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model2.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c33beb7a972464f8dcf977fbc2b3c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model3_params = {\n",
    "    \"hidden_layer_sizes\":(128, 128),\n",
    "    \"alpha\":0.01, \n",
    "    \"learning_rate_init\": 0.001\n",
    "    }\n",
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model3 = NeuralNetwork(nn_model3_params)\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model3.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Workflow\n",
    "\n",
    "Here you could see how it works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=[nn_model1, nn_model2, nn_model3], dataset=dataset_train, max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4, State history: [-0.00799365  1.43109277 -0.43077302  0.36261339 -0.02471587  0.07597064\n",
      "  0.          0.        ]\n",
      "Step: 5, State history: [-0.020135    1.42896844 -0.47974141  0.34353693 -0.04914006  0.12348212\n",
      "  0.          0.        ]\n",
      "Step: 6, State history: [-0.02063704  1.49531107 -0.5347775   0.36369197  0.00942229  0.06014732\n",
      "  0.          0.        ]\n",
      "Step: 7, State history: [-0.0441081   1.4740501  -0.53140469  0.34319195  0.0581589   0.05496297\n",
      "  0.          0.        ]\n",
      "Step: 8, State history: [-0.03686068  1.43536405 -0.46924847  0.30872668  0.04788847  0.13928711\n",
      "  0.          0.        ]\n",
      "Step: 9, State history: [-0.04486147  1.45026552 -0.45808422  0.24156467  0.05471485  0.16023316\n",
      "  0.          0.        ]\n",
      "Step: 10, State history: [-0.05183768  1.51144444 -0.4933244   0.26615997  0.08147543  0.11819338\n",
      "  0.          0.        ]\n",
      "Step: 11, State history: [-0.04323971  1.48465514 -0.51441555  0.18004638  0.06444473  0.13596467\n",
      "  0.          0.        ]\n",
      "Step: 12, State history: [-0.06358569  1.49321036 -0.50174963  0.16160946  0.06164297  0.10869757\n",
      "  0.          0.        ]\n",
      "Step: 13, State history: [-0.05803245  1.50191183 -0.47653525  0.11918015  0.0654752   0.03291954\n",
      "  0.          0.        ]\n",
      "Step: 14, State history: [-0.06542928  1.49222121 -0.48605403  0.116828    0.06654999  0.08951927\n",
      "  0.          0.        ]\n",
      "Step: 15, State history: [-0.07032095  1.48325305 -0.47746955  0.08311909  0.07316206  0.04358544\n",
      "  0.          0.        ]\n",
      "Step: 16, State history: [-0.07644498  1.49173002 -0.49209551  0.10353191  0.09107513 -0.00177023\n",
      "  0.          0.        ]\n",
      "Step: 17, State history: [-0.08708928  1.49702867 -0.48132721  0.09917227  0.07814466  0.02376327\n",
      "  0.          0.        ]\n",
      "Step: 18, State history: [-0.08681616  1.49019845 -0.48654613  0.04262672  0.07300547 -0.04291184\n",
      "  0.          0.        ]\n",
      "Step: 19, State history: [-0.09211378  1.50451102 -0.49552327  0.00239255  0.11008065 -0.06933326\n",
      "  0.          0.        ]\n",
      "Step: 20, State history: [-0.1015289   1.49552083 -0.48089099 -0.01833469  0.0636543  -0.06622948\n",
      "  0.          0.        ]\n",
      "Step: 21, State history: [-9.74624909e-02  1.49330610e+00 -5.25208296e-01 -6.88263411e-02\n",
      "  6.30138303e-02 -4.14021579e-04  0.00000000e+00  0.00000000e+00]\n",
      "Step: 22, State history: [-0.11064013  1.47075009 -0.49077313 -0.08620007  0.08797014  0.0635191\n",
      "  0.          0.        ]\n",
      "Step: 23, State history: [-0.11890046  1.48371298 -0.52195793 -0.13930874  0.07552252  0.07069932\n",
      "  0.          0.        ]\n",
      "Step: 24, State history: [-1.19164149e-01  1.48211405e+00 -4.93615709e-01 -1.57986057e-01\n",
      "  7.66315185e-02  1.47233832e-03  0.00000000e+00  0.00000000e+00]\n",
      "Step: 25, State history: [-0.12220484  1.4985263  -0.49614168 -0.17325995  0.09148354  0.04251215\n",
      "  0.          0.        ]\n",
      "Step: 26, State history: [-0.12392859  1.47129291 -0.4931691  -0.25347414  0.08106118  0.055966\n",
      "  0.          0.        ]\n",
      "Step: 27, State history: [-0.13142575  1.468008   -0.51923978 -0.25178805  0.0891018   0.02959289\n",
      "  0.          0.        ]\n",
      "Step: 28, State history: [-0.14262868  1.4506631  -0.47779901 -0.30050866  0.10002587 -0.01310279\n",
      "  0.          0.        ]\n",
      "Step: 29, State history: [-0.14617324  1.44601189 -0.51499967 -0.32038097  0.07676436  0.02363755\n",
      "  0.          0.        ]\n",
      "Step: 30, State history: [-0.14636863  1.43281574 -0.48890955 -0.35032256  0.05385299  0.0330462\n",
      "  0.          0.        ]\n",
      "Step: 31, State history: [-0.16048938  1.41931731 -0.49147418 -0.34752489  0.08171031 -0.01754359\n",
      "  0.          0.        ]\n",
      "Step: 32, State history: [-0.15984269  1.41827166 -0.48750051 -0.35906054  0.09078667 -0.0121298\n",
      "  0.          0.        ]\n",
      "Step: 33, State history: [-0.16044523  1.41382512 -0.50116509 -0.35740736  0.1174975   0.01745748\n",
      "  0.          0.        ]\n",
      "Step: 34, State history: [-0.16869867  1.3969944  -0.47642124 -0.37076977  0.09063054  0.03707402\n",
      "  0.          0.        ]\n",
      "Step: 35, State history: [-0.17647692  1.39955709 -0.49562787 -0.40699689  0.08556554  0.03625338\n",
      "  0.          0.        ]\n",
      "Step: 36, State history: [-0.1738077   1.36356581 -0.50107336 -0.43326509  0.08979208 -0.01536622\n",
      "  0.          0.        ]\n",
      "Step: 37, State history: [-0.18249956  1.37217376 -0.5050282  -0.45808826  0.07992528 -0.05189578\n",
      "  0.          0.        ]\n",
      "Step: 38, State history: [-0.19286332  1.37913369 -0.50730089 -0.4415517   0.06663488 -0.05447123\n",
      "  0.          0.        ]\n",
      "Step: 39, State history: [-0.18767802  1.33609031 -0.51321259 -0.42319902  0.07791946 -0.05047439\n",
      "  0.          0.        ]\n",
      "Step: 40, State history: [-0.20260142  1.34616316 -0.48266525 -0.45474237  0.04903048 -0.06508722\n",
      "  0.          0.        ]\n",
      "Step: 41, State history: [-0.20104597  1.34395577 -0.49800274 -0.43795814  0.0702128  -0.06595219\n",
      "  0.          0.        ]\n",
      "Step: 42, State history: [-0.20775426  1.31495404 -0.50822736 -0.49313587  0.09040481 -0.09312991\n",
      "  0.          0.        ]\n",
      "Step: 43, State history: [-0.21848656  1.31579586 -0.48904581 -0.53498572  0.0653351  -0.12395936\n",
      "  0.          0.        ]\n",
      "Step: 44, State history: [-0.2195036   1.2783132  -0.47211878 -0.54333092  0.05440563 -0.1660559\n",
      "  0.          0.        ]\n",
      "Step: 45, State history: [-0.22153488  1.27745518 -0.48931425 -0.58419822  0.03880248 -0.17058393\n",
      "  0.          0.        ]\n",
      "Step: 46, State history: [-0.22797035  1.25632915 -0.47791885 -0.60615632  0.05543247 -0.1169711\n",
      "  0.          0.        ]\n",
      "Step: 47, State history: [-0.24169084  1.25477794 -0.47085113 -0.62795561  0.01953503 -0.18309024\n",
      "  0.          0.        ]\n",
      "Step: 48, State history: [-0.24395748  1.25016312 -0.4702685  -0.65378024  0.02503006 -0.23229329\n",
      "  0.          0.        ]\n",
      "Step: 49, State history: [-0.24307517  1.224802   -0.47358572 -0.71543769 -0.03571727 -0.29722981\n",
      "  0.          0.        ]\n",
      "Step: 50, State history: [-0.24412782  1.21738191 -0.45237184 -0.71371364 -0.02520207 -0.24096456\n",
      "  0.          0.        ]\n",
      "Step: 51, State history: [-0.25475681  1.20020933 -0.44818633 -0.75301273 -0.03667782 -0.29513147\n",
      "  0.          0.        ]\n",
      "Step: 52, State history: [-0.26023566  1.15616623 -0.47042451 -0.77823072 -0.016303   -0.22733579\n",
      "  0.          0.        ]\n",
      "Step: 53, State history: [-0.26285602  1.17708135 -0.45482847 -0.8058455  -0.04218466 -0.1887603\n",
      "  0.          0.        ]\n",
      "Step: 54, State history: [-0.26660099  1.12457726 -0.4742409  -0.8308317  -0.03222523 -0.2387598\n",
      "  0.          0.        ]\n",
      "Step: 55, State history: [-0.26972621  1.09917862 -0.43021664 -0.8379607  -0.06984356 -0.24548249\n",
      "  0.          0.        ]\n",
      "Step: 56, State history: [-0.27686863  1.08470476 -0.45179648 -0.8237693  -0.09477916 -0.24146598\n",
      "  0.          0.        ]\n",
      "Step: 57, State history: [-0.28063032  1.07840196 -0.43711294 -0.82086948 -0.10892992 -0.26117239\n",
      "  0.          0.        ]\n",
      "Step: 58, State history: [-0.28358182  1.08266781 -0.44888779 -0.80391871 -0.09259267 -0.23982932\n",
      "  0.          0.        ]\n",
      "Step: 59, State history: [-0.28711228  1.02916897 -0.41110044 -0.81064675 -0.15997514 -0.25442879\n",
      "  0.          0.        ]\n",
      "Step: 60, State history: [-0.29647031  1.00696593 -0.36790025 -0.85225781 -0.17348918 -0.29835772\n",
      "  0.          0.        ]\n",
      "Step: 61, State history: [-0.30377709  1.00430961 -0.40935523 -0.8717075  -0.17706396 -0.24049751\n",
      "  0.          0.        ]\n",
      "Step: 62, State history: [-0.3024193   0.96056809 -0.42463395 -0.87427648 -0.20712422 -0.23036099\n",
      "  0.          0.        ]\n",
      "Step: 63, State history: [-0.31333758  0.96574003 -0.42573032 -0.90579416 -0.16283444 -0.29911198\n",
      "  0.          0.        ]\n",
      "Step: 64, State history: [-0.30639156  0.94602463 -0.38839122 -0.88539039 -0.18155395 -0.30312375\n",
      "  0.          0.        ]\n",
      "Step: 65, State history: [-0.31481329  0.89926178 -0.38854062 -0.91888661 -0.23689304 -0.27384077\n",
      "  0.          0.        ]\n",
      "Step: 66, State history: [-0.31942048  0.8612332  -0.38487253 -0.96854424 -0.27470962 -0.24539224\n",
      "  0.          0.        ]\n",
      "Step: 67, State history: [-0.32423466  0.8556405  -0.39137035 -1.00281217 -0.25665776 -0.27313849\n",
      "  0.          0.        ]\n",
      "Step: 68, State history: [-0.32806132  0.83720761 -0.36474249 -1.02160121 -0.29803803 -0.30441406\n",
      "  0.          0.        ]\n",
      "Step: 69, State history: [-0.3291188   0.81257918 -0.39846721 -1.05465629 -0.30136061 -0.24052448\n",
      "  0.          0.        ]\n",
      "Step: 70, State history: [-0.33601299  0.78669085 -0.37968564 -1.10099775 -0.27141131 -0.27741864\n",
      "  0.          0.        ]\n",
      "Step: 71, State history: [-0.33824594  0.74254129 -0.37710381 -1.08662353 -0.3104119  -0.24269001\n",
      "  0.          0.        ]\n",
      "Step: 72, State history: [-0.34029051  0.71662568 -0.3834962  -1.0807575  -0.38087305 -0.27782406\n",
      "  0.          0.        ]\n",
      "Step: 73, State history: [-0.34656948  0.69848675 -0.38859142 -1.12026286 -0.31967571 -0.23595159\n",
      "  0.          0.        ]\n",
      "Step: 74, State history: [-0.35347656  0.65923697 -0.41704026 -1.15882585 -0.3480926  -0.19437265\n",
      "  0.          0.        ]\n",
      "Step: 75, State history: [-0.34813667  0.66157262 -0.44861697 -1.17608167 -0.33721451 -0.16917665\n",
      "  0.          0.        ]\n",
      "Step: 76, State history: [-0.36071081  0.60165469 -0.41293995 -1.14664239 -0.34915952 -0.09047723\n",
      "  0.          0.        ]\n",
      "Step: 77, State history: [-0.36311088  0.59387552 -0.43074057 -1.20129865 -0.38794013 -0.04984448\n",
      "  0.          0.        ]\n",
      "Step: 78, State history: [-0.37316572  0.54902095 -0.39053153 -1.17395434 -0.3949063  -0.0836222\n",
      "  0.          0.        ]\n",
      "Step: 79, State history: [-0.37608163  0.52950247 -0.34896647 -1.21449732 -0.35734246 -0.05341331\n",
      "  0.          0.        ]\n",
      "Step: 80, State history: [-0.37554466  0.4870606  -0.3648591  -1.21461897 -0.37055551 -0.03673759\n",
      "  0.          0.        ]\n",
      "Step: 81, State history: [-0.38269937  0.46076266 -0.42036845 -1.32989129 -0.40073018  0.01583958\n",
      "  0.          0.        ]\n",
      "Step: 82, State history: [-0.38532242  0.44605147 -0.39460566 -1.29250816 -0.37654642 -0.04209002\n",
      "  0.          0.        ]\n",
      "Step: 83, State history: [-0.38184055  0.42913784 -0.37380014 -1.28030448 -0.40061097 -0.01314766\n",
      "  0.          0.        ]\n",
      "Step: 84, State history: [-0.39112621  0.38319248 -0.43287443 -1.31673566 -0.37146043  0.07402357\n",
      "  0.          0.        ]\n",
      "Step: 85, State history: [-0.39288768  0.3622716  -0.42338866 -1.30087171 -0.36768135  0.03845404\n",
      "  0.          0.        ]\n",
      "Step: 86, State history: [-0.40362713  0.31300261 -0.36763647 -1.33378374 -0.33052409  0.0384065\n",
      "  0.          0.        ]\n",
      "Step: 87, State history: [-0.40339686  0.29191527 -0.30854877 -1.27570118 -0.35423325  0.04048299\n",
      "  0.          0.        ]\n",
      "Step: 88, State history: [-0.40716544  0.26195125 -0.29391748 -1.25849357 -0.35409415  0.05685438\n",
      "  0.          0.        ]\n",
      "Step: 89, State history: [-0.4088687   0.22124011 -0.29838753 -1.33293337 -0.35929243 -0.0106313\n",
      "  0.          0.        ]\n",
      "Step: 90, State history: [-0.41535679  0.2046295  -0.28300087 -1.36044014 -0.37058652 -0.00548671\n",
      "  0.          0.        ]\n",
      "Step: 91, State history: [-0.41356546  0.1850658  -0.32641102 -1.39691323 -0.35740932 -0.06897125\n",
      "  0.          0.        ]\n",
      "Step: 92, State history: [-0.4167678   0.14216153 -0.36279744 -1.3916084  -0.31527931 -0.07727982\n",
      "  0.          0.        ]\n",
      "Step: 93, State history: [-0.41793054  0.1185044  -0.28404367 -1.46174552 -0.36979693 -0.04995401\n",
      "  0.          0.        ]\n",
      "Step: 94, State history: [-0.42626289  0.08433984 -0.31624603 -1.5067205  -0.30837864 -0.03967985\n",
      "  0.          0.        ]\n",
      "Step: 95, State history: [-0.42642992  0.01589287 -0.31858732 -1.51562301 -0.31920181 -0.0349012\n",
      "  0.          0.        ]\n",
      "Step: 96, State history: [-4.29185310e-01 -2.13672630e-02 -3.30101061e-01 -1.49604339e+00\n",
      " -3.01677036e-01  6.01710801e-04  0.00000000e+00  0.00000000e+00]\n",
      "Step: 97, State history: [-0.43467676 -0.01244083 -0.25779928 -1.58623587 -0.31204403 -0.15042351\n",
      "  0.          0.        ]\n",
      "Step: 98, State history: [-0.43758991 -0.07155531 -0.3078343  -1.63937532 -0.37609806 -0.21983736\n",
      "  0.          0.        ]\n",
      "Step: 99, State history: [-0.44073921 -0.07139718 -0.23202332 -1.59865637 -0.35680822 -0.13144939\n",
      "  0.          0.        ]\n",
      "Step: 100, State history: [-0.43834367 -0.13680055 -0.21327337 -1.60882734 -0.34870094 -0.1513424\n",
      "  1.          0.        ]\n",
      "Step: 101, State history: [-0.44577026 -0.21420422 -0.29592532 -1.22627199 -0.33488725 -0.559559\n",
      "  1.          0.        ]\n",
      "Step: 102, State history: [-0.45305276 -0.16735817 -0.23467967 -0.41328771 -0.40767056  1.90066665\n",
      "  1.          0.        ]\n",
      "-131.5952259055514\n"
     ]
    }
   ],
   "source": [
    "obs, _ = sim_env.reset()\n",
    "total_reward = 0\n",
    "for _ in range(200):\n",
    "    action = sim_env.action_space.sample()\n",
    "    obs, reward, done, done, info = sim_env.step(action)\n",
    "    total_reward += reward\n",
    "    sim_env.render(\"human\")\n",
    "    if done:\n",
    "        break\n",
    "sim_env.close()\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49       |\n",
      "|    ep_rew_mean     | -171     |\n",
      "| time/              |          |\n",
      "|    fps             | 161      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.9        |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005098087 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00506     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.27e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-203.55 +/- 93.79\n",
      "Episode length: 88.40 +/- 18.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 88.4         |\n",
      "|    mean_reward          | -204         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053049806 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.0108      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 2.03e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 52.7     |\n",
      "|    ep_rew_mean     | -159     |\n",
      "| time/              |          |\n",
      "|    fps             | 124      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 6144     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.8         |\n",
      "|    ep_rew_mean          | -154         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 120          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073420852 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.00831     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 553          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    value_loss           | 2.2e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-410.59 +/- 136.90\n",
      "Episode length: 112.20 +/- 13.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 112         |\n",
      "|    mean_reward          | -411        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008096465 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.0218     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 791         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    value_loss           | 2.12e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 63.1     |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    fps             | 118      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65.9         |\n",
      "|    ep_rew_mean          | -195         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046849726 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -0.0162      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.89e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    value_loss           | 6.87e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.3        |\n",
      "|    ep_rew_mean          | -231        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010292126 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.000275   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 941         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-203.24 +/- 83.21\n",
      "Episode length: 131.00 +/- 45.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 131         |\n",
      "|    mean_reward          | -203        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008298904 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.68e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 6.42e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    fps             | 114      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 142      |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.8         |\n",
      "|    ep_rew_mean          | -267         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069691157 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -0.000471    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 637          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    value_loss           | 2.5e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-303.28 +/- 150.96\n",
      "Episode length: 117.60 +/- 13.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 118          |\n",
      "|    mean_reward          | -303         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042212233 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -0.00312     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.01e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 1.26e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 58.8     |\n",
      "|    ep_rew_mean     | -272     |\n",
      "| time/              |          |\n",
      "|    fps             | 113      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.9         |\n",
      "|    ep_rew_mean          | -297         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022019811 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.00046     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.4e+03      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 1e+04        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.2         |\n",
      "|    ep_rew_mean          | -254         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045196163 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -0.000422    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 540          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 4.51e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-142.90 +/- 82.06\n",
      "Episode length: 139.20 +/- 34.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 139          |\n",
      "|    mean_reward          | -143         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 25000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124806855 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 2.68e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 379          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00829     |\n",
      "|    value_loss           | 853          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 69.5     |\n",
      "|    ep_rew_mean     | -191     |\n",
      "| time/              |          |\n",
      "|    fps             | 112      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 26624    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68           |\n",
      "|    ep_rew_mean          | -166         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070680035 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | -1.24e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.45e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00085     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-145.69 +/- 83.27\n",
      "Episode length: 105.40 +/- 26.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 105          |\n",
      "|    mean_reward          | -146         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014542416 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -0.00149     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.81e+03     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 5.71e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 73.6     |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    fps             | 111      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 275      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7de8df360c70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import gymnasium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "# Monkey-patch gym to include a __version__ attribute if it's missing.\n",
    "\n",
    "# Set up log folder for monitoring\n",
    "log_dir = \"./logs_dir/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create the training environment and wrap it with a Monitor to log rewards.\n",
    "train_env = sim_env\n",
    "train_env = Monitor(train_env, log_dir)\n",
    "\n",
    "# Create a separate evaluation environment.\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "eval_env = Monitor(eval_env, log_dir)\n",
    "\n",
    "# Set up the evaluation callback. This will evaluate the model every 5000 timesteps,\n",
    "# and save the model if it achieves a new best mean reward.\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=os.path.join(log_dir, 'best_model'),\n",
    "    log_path=log_dir,\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=5,\n",
    "    deterministic=False,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model and use the evaluation callback to save the best model.\n",
    "model.learn(total_timesteps=30000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = PPO.load(os.path.join(log_dir, 'best_model/best_model.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -251.36562273417067\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"human\")   \n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "terminated = False\n",
    "total_reward = 0\n",
    "while not (done or terminated):\n",
    "    # Predict the next action using the trained policy.\n",
    "    action, _ = best_model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, terminated ,_ = env.step(action)\n",
    "    total_reward += reward\n",
    "    env.render()\n",
    "\n",
    "env.close()\n",
    "print(f\"Total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -356.7004370579849\n",
      "Total reward: -205.0672176445213\n",
      "Total reward: -185.42442994538737\n",
      "Total reward: -180.583259349532\n",
      "Total reward: -74.3874245609765\n",
      "Total reward: -131.11515657040428\n",
      "Total reward: -328.54980789341494\n",
      "Total reward: -15.775288461501205\n",
      "Total reward: -250.72430317604957\n",
      "Total reward: -344.161095402511\n",
      "Total reward: -378.00936461893\n",
      "Total reward: -163.0313261288647\n",
      "Total reward: -344.6415081425979\n",
      "Total reward: -193.39735169148756\n",
      "Total reward: -84.7045404038461\n",
      "Total reward: -87.1937146048694\n",
      "Total reward: -51.40288570194947\n",
      "Total reward: -120.21858425173662\n",
      "Total reward: -259.98012877021154\n",
      "Total reward: -186.32341640938367\n",
      "Total reward: -114.7653707964826\n",
      "Total reward: -275.9906541269082\n",
      "Total reward: -53.82357769370684\n",
      "Total reward: -80.98208635387768\n",
      "Total reward: -191.41037610373314\n",
      "Total reward: -329.2542637683055\n",
      "Total reward: -158.78980841539396\n",
      "Total reward: -204.61298171309147\n",
      "Total reward: -312.3517801164194\n",
      "Total reward: -142.3654677531664\n",
      "Total reward: -55.04892807117675\n",
      "Total reward: -430.3062885880578\n",
      "Total reward: -42.89884839202232\n",
      "Total reward: -209.8704608737832\n",
      "Total reward: -77.56181864028197\n",
      "Total reward: 63.661134614408766\n",
      "Total reward: -268.4924328292195\n",
      "Total reward: -70.48852829271024\n",
      "Total reward: -318.7763479870955\n",
      "Total reward: -313.4008173894811\n",
      "Total reward: -362.68431901702536\n",
      "Total reward: -288.7232172090236\n",
      "Total reward: -194.99812573912806\n",
      "Total reward: -200.6813594746174\n",
      "Total reward: -222.38719243464897\n",
      "Total reward: -129.9334937318314\n",
      "Total reward: -116.64842408244147\n",
      "Total reward: -97.56992457219121\n",
      "Total reward: -326.28541706892713\n",
      "Total reward: -160.59942374268377\n",
      "Total reward: -353.19476523567266\n",
      "Total reward: -258.6307255108362\n",
      "Total reward: -105.96795758158892\n",
      "Total reward: -53.70048746756849\n",
      "Total reward: -198.2576296983044\n",
      "Total reward: -235.28191880446613\n",
      "Total reward: -4.521021581743469\n",
      "Total reward: -350.3812665251879\n",
      "Total reward: -263.2316774415074\n",
      "Total reward: -9.845840596214785\n",
      "Total reward: 33.21802223034649\n",
      "Total reward: -165.43600369141106\n",
      "Total reward: -90.02027707774748\n",
      "Total reward: -95.38702439253076\n",
      "Total reward: -234.5830666719871\n",
      "Total reward: -160.33133258113799\n",
      "Total reward: -270.717761970801\n",
      "Total reward: -20.06075874082474\n",
      "Total reward: -171.96022731324092\n",
      "Total reward: -219.80220226196207\n",
      "Total reward: -248.85435894998136\n",
      "Total reward: -320.95144049881935\n",
      "Total reward: -339.6469001702745\n",
      "Total reward: -333.161333172828\n",
      "Total reward: -132.95932167723595\n",
      "Total reward: -36.25597648689248\n",
      "Total reward: -217.4753822842939\n",
      "Total reward: -190.5832913197711\n",
      "Total reward: -33.09769991925319\n",
      "Total reward: -159.51212527465964\n",
      "Total reward: -257.06142925107406\n",
      "Total reward: -63.548679083540534\n",
      "Total reward: -69.71900853220544\n",
      "Total reward: -281.378871405362\n",
      "Total reward: -100.88060336072968\n",
      "Total reward: -160.2169189095829\n",
      "Total reward: -0.24357787513930873\n",
      "Total reward: -98.21496765155844\n",
      "Total reward: -76.46601537225911\n",
      "Total reward: -103.41016850643769\n",
      "Total reward: -61.27020406763299\n",
      "Total reward: -174.52465006102216\n",
      "Total reward: -196.01710028379114\n",
      "Total reward: -86.89901658449057\n",
      "Total reward: -428.60819474069825\n",
      "Total reward: -112.63563468368008\n",
      "Total reward: -63.87988621510978\n",
      "Total reward: -145.98817153354844\n",
      "Total reward: -243.91225783192291\n",
      "Total reward: -59.91767602526326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"rgb_array\")  \n",
    "all_rewards = []\n",
    "for i in range(100):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    terminated = False\n",
    "    total_reward = 0\n",
    "    while not (done or terminated):\n",
    "        # Predict the next action using the trained policy.\n",
    "        action, _ = best_model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, terminated ,_ = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "    all_rewards.append(total_reward)\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1 model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mall_rewards\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_rewards' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 1 model\n",
    "np.mean(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">No eval environment provided, will not create eval callback</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Creating PPO model</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Training model</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.1     |\n",
      "|    ep_rew_mean     | -188     |\n",
      "| time/              |          |\n",
      "|    fps             | 165      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.1        |\n",
      "|    ep_rew_mean          | -179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005396694 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.000943   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 5.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.3        |\n",
      "|    ep_rew_mean          | -179        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005316759 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.0151     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 3.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.1         |\n",
      "|    ep_rew_mean          | -152         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 120          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059854724 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -0.0214      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 6.48e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52          |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008362556 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 4.92e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 854         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.4        |\n",
      "|    ep_rew_mean          | -127        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011058262 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.00186    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 464         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    value_loss           | 778         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pi_optimal.planners.online_planner import OnlinePlanner\n",
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=[nn_model1, nn_model2, nn_model3], dataset=dataset_train, max_episode_steps=200)\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "\n",
    "online_planner = OnlinePlanner(env=sim_env, eval_env=None, train_params={\"total_timesteps\": 11000}, eval_params={\"n_eval_episodes\": 2, \"eval_freq\": 5000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Inference from a dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details  look in to the predict function of the planer. It takes the last observation and uses it as observation. Ensure that the dataset is set to **is_inference == True** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 6651.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 50 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 1 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Using processors provided in the dataset_configuration.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean -0.04 and std 0.31'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_inf = data_collector.collect(n_steps=50, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "\n",
    "dataset_inf = dataset_test = TimeseriesDataset(\n",
    "    df=df_inf,\n",
    "    dataset_config=dataset_config,\n",
    "    train_processors=False,\n",
    "    is_inference=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_planner.plan(dataset_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi-research-HSEt-N2e-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
