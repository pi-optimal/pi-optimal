{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "Import required libraries including NumPy, sklearn with Intel extension, and pi_optimal utilities. Configure warning suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment and Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "#from sklearnex import patch_sklearn\n",
    "import warnings\n",
    "\n",
    "# Change directory to the parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Apply Intel extension to sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import pi_optimal utilities\n",
    "from pi_optimal.utils.data_generators.gym_data_generator import GymDataGenerator\n",
    "from pi_optimal.datasets.timeseries_dataset import TimeseriesDataset\n",
    "from pi_optimal.models.random_forest_model import RandomForest\n",
    "from pi_optimal.models.mlp import NeuralNetwork\n",
    "from pi_optimal.evaluators.base_evaluator import BaseEvaluator\n",
    "from pi_optimal.evaluators.plotting import plot_n_step_evaluation, plot_n_step_episode_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gym Data Generator\n",
    "Initialize GymDataGenerator with LunarLander environment and collect training and test data with specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 36515.39it/s]\n",
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00<00:00, 50735.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create Gym Data Generator\n",
    "\n",
    "# Initialize GymDataGenerator with LunarLander environment\n",
    "data_collector = GymDataGenerator(env_name=\"LunarLander-v3\")\n",
    "\n",
    "# Collect training data\n",
    "df_train = data_collector.collect(n_steps=10000, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "df_test = data_collector.collect(n_steps=5000, max_steps_per_episode=200, env_seed=None, action_seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Dataset Parameters\n",
    "Set up dataset configuration dictionary defining features, processors, and evaluation metrics for states, actions, and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Dataset Parameters\n",
    "\n",
    "# Define dataset configuration dictionary\n",
    "dataset_config = {\n",
    "    \"episode_column\": \"episode\",\n",
    "    \"timestep_column\": \"step\",\n",
    "    \"states\": {\n",
    "        0: {\"name\": \"state_0\", \"type\": \"numerical\", \"processor\": {\"name\": \"StandardScaler\"}, \"evaluation_metric\": \"mae\"},\n",
    "        1: {\"name\": \"state_1\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        2: {\"name\": \"state_2\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        3: {\"name\": \"state_3\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        4: {\"name\": \"state_4\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        5: {\"name\": \"state_5\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        6: {\"name\": \"state_6\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        7: {\"name\": \"state_7\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        8: {\"name\": \"done\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        9: {\"name\": \"reward\", \"type\": \"numerical\", \"processor\": {\"name\": \"PowerTransformer\"}, \"evaluation_metric\": \"mae\"},\n",
    "    },\n",
    "    \"actions\": {\n",
    "        0: {\"name\": \"action_0\", \"type\": \"categorial\", \"processor\": {\"name\": \"OneHotEncoder\"}},\n",
    "    },\n",
    "    \"reward_feature_idx\": 9,\n",
    "    \"reward_vector_idx\": 9,\n",
    "    \"reward_column\": \"reward\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Test Datasets\n",
    "Initialize TimeseriesDataset objects with collected data, applying the configuration and setting lookback/forecast windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 1000 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 11 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Fitting feature processors...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Processors created and fitted</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean 0.11 and std 0.33'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 5000 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 52 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Using processors provided in the dataset_configuration.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean 0.11 and std 0.33'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Training and Test Datasets\n",
    "\n",
    "# Define lookback and forecast timesteps\n",
    "LOOKBACK_TIMESTEPS = 10\n",
    "FORECAST_TIMESTEPS = 1\n",
    "\n",
    "# Initialize TimeseriesDataset objects for training and test data\n",
    "dataset_train = TimeseriesDataset(\n",
    "    df=df_train,\n",
    "    dataset_config=dataset_config,\n",
    "    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "    forecast_timesteps=FORECAST_TIMESTEPS,\n",
    "    train_processors=True\n",
    ")\n",
    "\n",
    "\n",
    "dataset_test = TimeseriesDataset(\n",
    "    df=df_test,\n",
    "    dataset_config=dataset_config,\n",
    "    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "    forecast_timesteps=FORECAST_TIMESTEPS,\n",
    "    train_processors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network Model\n",
    "Create and train a Neural Network model with specified hyperparameters on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0dd4ff63024277b83e0eeaaa7080e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model1 = NeuralNetwork(\n",
    "    hidden_layer_sizes=(128, 128),\n",
    "    alpha=0.01, \n",
    "    learning_rate_init=0.001,\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model1.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12edf5721d944a5d960e3865b70f3547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model2 = NeuralNetwork(\n",
    "    hidden_layer_sizes=(128, 128),\n",
    "    alpha=0.01, \n",
    "    learning_rate_init=0.001,\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model2.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaab99200d8b470e9e209ecbaa7200f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model3 = NeuralNetwork(\n",
    "    hidden_layer_sizes=(128, 128),\n",
    "    alpha=0.01, \n",
    "    learning_rate_init=0.001,\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model3.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Workflow\n",
    "\n",
    "Here you could see how it works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=[nn_model1, nn_model2, nn_model3], dataset=dataset_train, max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 23, State history: [ 0.09052636  1.30892165  0.45619737 -0.41948996 -0.11548094 -0.23644299\n",
      "  0.          0.        ]\n",
      "Step: 24, State history: [ 0.10001343  1.2771997   0.47070809 -0.35508364 -0.12485919 -0.1554039\n",
      "  0.          0.        ]\n",
      "Step: 25, State history: [ 0.05861678  1.26663382  0.3602799  -0.50082229 -0.27455575 -0.17481056\n",
      "  0.          0.        ]\n",
      "Step: 26, State history: [ 0.07945819  1.20570933  0.4363852  -0.41628732 -0.15712475 -0.15456128\n",
      "  0.          0.        ]\n",
      "Step: 27, State history: [ 0.0958831   1.25613371  0.57484813 -0.49003895 -0.13376869 -0.36245045\n",
      "  0.          0.        ]\n",
      "Step: 28, State history: [ 0.07742128  1.1195561   0.57236157 -0.51228361 -0.2498309  -0.1256556\n",
      "  0.          0.        ]\n",
      "Step: 29, State history: [ 0.12695883  1.14332263  0.42385142 -0.39039625 -0.20690076 -0.16220965\n",
      "  0.          0.        ]\n",
      "Step: 30, State history: [ 0.07692196  1.1128045   0.61450024 -0.46367135 -0.26626612 -0.20658028\n",
      "  0.          0.        ]\n",
      "Step: 31, State history: [ 0.09587723  1.22518016  0.7281569  -0.4543177  -0.39872226 -0.23142737\n",
      "  0.          0.        ]\n",
      "Step: 32, State history: [ 0.08720882  1.16904274  0.51921686 -0.44936884 -0.20781076 -0.22584163\n",
      "  0.          0.        ]\n",
      "Step: 33, State history: [ 0.08906142  1.16300353  0.40758278 -0.39724609 -0.18908233 -0.23896606\n",
      "  0.          0.        ]\n",
      "Step: 34, State history: [ 0.10453146  1.10019346  0.63185769 -0.41190001 -0.33945874 -0.40133153\n",
      "  0.          0.        ]\n",
      "Step: 35, State history: [ 0.12383054  1.124768    0.70608795 -0.53866114 -0.60563337 -0.4360766\n",
      "  0.          0.        ]\n",
      "Step: 36, State history: [ 0.10032461  1.15288917  0.61879237 -0.57540796 -0.32030192 -0.34304227\n",
      "  0.          0.        ]\n",
      "Step: 37, State history: [ 0.11098479  1.13742725  0.57688174 -0.42974949 -0.32927848 -0.27918841\n",
      "  0.          0.        ]\n",
      "Step: 38, State history: [ 0.17065432  1.15651086  0.58060202 -0.57212468 -0.16296783 -0.22876349\n",
      "  0.          0.        ]\n",
      "Step: 39, State history: [ 0.14629571  1.13696473  0.79020717 -0.44194093 -0.34939706 -0.19471909\n",
      "  0.          0.        ]\n",
      "Step: 40, State history: [ 0.1409997   0.95384666  0.71107881 -0.67092971 -0.34547276 -0.3568604\n",
      "  0.          0.        ]\n",
      "Step: 41, State history: [ 0.16705973  1.09851128  0.58214561 -0.41554886 -0.4488055  -0.30533567\n",
      "  0.          0.        ]\n",
      "Step: 42, State history: [ 0.19498161  1.02460852  0.6652479  -0.56085642 -0.40456674 -0.29683312\n",
      "  0.          0.        ]\n",
      "Step: 43, State history: [ 0.18563353  1.23669212  0.85786319 -0.5821118  -0.48139299 -0.40941427\n",
      "  0.          0.        ]\n",
      "Step: 44, State history: [ 0.1748583   1.19641027  0.73633097 -0.52195666 -0.50260293 -0.32136118\n",
      "  0.          0.        ]\n",
      "Step: 45, State history: [ 0.18131936  0.99727145  0.66196244 -0.55259064 -0.51066846 -0.2796154\n",
      "  0.          0.        ]\n",
      "Step: 46, State history: [ 0.1536566   1.06010551  0.69354327 -0.63561668 -0.48097289 -0.36347825\n",
      "  0.          0.        ]\n",
      "Step: 47, State history: [ 0.2103765   1.10735097  0.70484839 -0.6760277  -0.48864396 -0.25678655\n",
      "  0.          0.        ]\n",
      "Step: 48, State history: [ 0.20624801  1.00462616  0.77158664 -0.62305029 -0.4809222  -0.16673458\n",
      "  0.          0.        ]\n",
      "Step: 49, State history: [ 0.21223591  1.01879793  0.51333932 -0.70995274 -0.41563092 -0.22433728\n",
      "  0.          0.        ]\n",
      "Step: 50, State history: [ 0.21148461  1.00161384  0.65289406 -0.65228552 -0.51920641 -0.23419442\n",
      "  0.          0.        ]\n",
      "Step: 51, State history: [ 0.2543522   1.00286511  0.70090519 -0.74002839 -0.47663188 -0.57294303\n",
      "  0.          0.        ]\n",
      "Step: 52, State history: [ 0.26016265  0.95850113  0.70401059 -0.70177222 -0.51487785 -0.42197176\n",
      "  0.          0.        ]\n",
      "Step: 53, State history: [ 0.27915837  1.02055136  0.80958307 -0.73759033 -0.47887993 -0.23329131\n",
      "  0.          0.        ]\n",
      "Step: 54, State history: [ 0.27140284  1.0627633   0.62923701 -0.80964871 -0.4926121  -0.30025075\n",
      "  0.          0.        ]\n",
      "Step: 55, State history: [ 0.23249487  1.00331618  0.70440184 -0.87059789 -0.50856928 -0.202997\n",
      "  0.          0.        ]\n",
      "Step: 56, State history: [ 0.29702814  0.89591643  0.66784912 -0.80496753 -0.46160541 -0.31373804\n",
      "  0.          0.        ]\n",
      "Step: 57, State history: [ 0.29125183  0.92224749  0.72190304 -0.95885447 -0.54725633 -0.27523289\n",
      "  0.          0.        ]\n",
      "Step: 58, State history: [ 0.30017366  0.78726195  0.8287996  -0.83981848 -0.54697096 -0.11052934\n",
      "  0.          0.        ]\n",
      "Step: 59, State history: [ 0.34175215  0.80430248  0.77151242 -0.87309031 -0.35153119 -0.12836519\n",
      "  0.          0.        ]\n",
      "Step: 60, State history: [ 0.33317884  0.87471211  0.69937736 -1.13524514 -0.50394849 -0.18707932\n",
      "  0.          0.        ]\n",
      "Step: 61, State history: [ 0.36049471  0.74363269  0.73221814 -0.95791991 -0.55565344 -0.09068305\n",
      "  0.          0.        ]\n",
      "Step: 62, State history: [ 0.36398857  0.71930901  0.70855438 -1.08309535 -0.51967744 -0.17023477\n",
      "  0.          0.        ]\n",
      "Step: 63, State history: [ 0.35056323  0.76470557  0.71894198 -0.89353438 -0.53942746 -0.03112961\n",
      "  0.          0.        ]\n",
      "Step: 64, State history: [ 0.34698901  0.77447499  0.79090241 -0.98656768 -0.50738681 -0.01109615\n",
      "  0.          0.        ]\n",
      "Step: 65, State history: [ 0.3611434   0.75068659  0.7856661  -1.19279145 -0.51064357 -0.00776239\n",
      "  0.          0.        ]\n",
      "Step: 66, State history: [ 0.35154321  0.50645549  0.87159735 -1.00523669 -0.57502312  0.11103943\n",
      "  0.          0.        ]\n",
      "Step: 67, State history: [ 0.4029478   0.71948459  0.70688853 -0.99760181 -0.57107411  0.15914191\n",
      "  0.          0.        ]\n",
      "Step: 68, State history: [ 0.4171768   0.57322354  0.84882224 -1.18403787 -0.47125846 -0.01211181\n",
      "  0.          0.        ]\n",
      "Step: 69, State history: [ 0.41699075  0.5548356   0.95817569 -1.1167605  -0.4464253   0.27129735\n",
      "  0.          0.        ]\n",
      "Step: 70, State history: [ 0.42557496  0.65733558  0.7661697  -1.1285158  -0.4724122   0.10227495\n",
      "  0.          0.        ]\n",
      "Step: 71, State history: [ 0.41989762  0.58111949  0.91597855 -1.15857092 -0.57758666 -0.0181396\n",
      "  0.          0.        ]\n",
      "Step: 72, State history: [ 0.44744764  0.5015407   0.95280025 -1.04358964 -0.54448132  0.13078575\n",
      "  0.          0.        ]\n",
      "Step: 73, State history: [ 0.44131314  0.44624122  0.94977552 -0.99815761 -0.53664034 -0.10330157\n",
      "  0.          0.        ]\n",
      "Step: 74, State history: [ 0.46046764  0.439197    0.94011118 -1.09511883 -0.53700029 -0.33627428\n",
      "  0.          0.        ]\n",
      "Step: 75, State history: [ 0.48097731  0.39532424  0.84962947 -1.19223125 -0.59450229 -0.12103201\n",
      "  0.          0.        ]\n",
      "Step: 76, State history: [ 0.49372306  0.44124564  0.99605562 -1.13866543 -0.41579509 -0.39662391\n",
      "  0.          0.        ]\n",
      "Step: 77, State history: [ 0.4960757   0.48232516  1.07122196 -1.02781954 -0.40309657 -0.13044335\n",
      "  0.          0.        ]\n",
      "Step: 78, State history: [ 0.49194588  0.41365088  1.00450353 -1.16859021 -0.54177887 -0.3458927\n",
      "  0.          0.        ]\n",
      "Step: 79, State history: [ 0.49146163  0.3121702   1.09242678 -1.21846887 -0.44467437 -0.65444413\n",
      "  0.          0.        ]\n",
      "Step: 80, State history: [ 0.51468476  0.45164396  1.05010486 -1.20432495 -0.67234725 -0.45676893\n",
      "  0.          0.        ]\n",
      "Step: 81, State history: [ 0.5474853   0.28874857  1.05353308 -1.24887969 -0.66548088 -0.5117725\n",
      "  0.          0.        ]\n",
      "Step: 82, State history: [ 0.52746715  0.33848124  1.0323791  -1.15593976 -0.72920061 -0.56969572\n",
      "  0.          0.        ]\n",
      "Step: 83, State history: [ 0.54166548  0.35025218  1.0476306  -1.21139154 -0.85925778 -0.36755368\n",
      "  0.          0.        ]\n",
      "Step: 84, State history: [ 0.52538122  0.23428411  1.09664112 -1.13290496 -0.76731442 -0.46063945\n",
      "  0.          0.        ]\n",
      "Step: 85, State history: [ 0.55713421  0.1581632   1.10738373 -1.17006928 -0.76280291 -0.73522803\n",
      "  0.          0.        ]\n",
      "Step: 86, State history: [ 0.57662011  0.29940966  1.22212451 -1.45681869 -0.94073494 -0.82222437\n",
      "  0.          0.        ]\n",
      "Step: 87, State history: [ 0.57184163  0.34156707  1.08761005 -1.39803473 -0.96176893 -0.74537753\n",
      "  0.          0.        ]\n",
      "Step: 88, State history: [ 0.59719721  0.19179853  1.15132197 -1.44433325 -1.04504581 -0.69939615\n",
      "  0.          0.        ]\n",
      "Step: 89, State history: [ 0.59435069  0.21912957  1.11859153 -1.25431491 -1.08380869 -0.52509046\n",
      "  0.          0.        ]\n",
      "Step: 90, State history: [ 0.60543471  0.28718255  1.19568896 -1.25809199 -0.92247557 -0.44206781\n",
      "  0.          0.        ]\n",
      "Step: 91, State history: [ 0.59040403  0.17186164  1.13565062 -1.30295079 -1.1087758  -0.72370522\n",
      "  0.          0.        ]\n",
      "Step: 92, State history: [ 0.6297777   0.14243517  1.14444458 -1.39182547 -0.98406013 -0.40752304\n",
      "  0.          0.        ]\n",
      "Step: 93, State history: [ 0.63045747  0.11441296  0.97686791 -1.37107163 -1.15832394 -0.67475223\n",
      "  1.          0.        ]\n",
      "Step: 94, State history: [ 0.6331985   0.17887088  1.14335994 -1.02885388 -1.40320103 -1.03548401\n",
      "  0.          0.        ]\n",
      "Step: 95, State history: [ 0.62388363  0.09526034  1.25290966 -1.11935617 -1.42486099 -0.57919331\n",
      "  0.          0.        ]\n",
      "Step: 96, State history: [ 6.61883225e-01  5.13214412e-04  1.29811267e+00 -1.11331469e+00\n",
      " -1.57858184e+00 -3.94600439e-01  0.00000000e+00  0.00000000e+00]\n",
      "Step: 97, State history: [ 0.63824143  0.01760194  1.14192336 -1.32638868 -1.38282244 -0.45993253\n",
      "  0.          0.        ]\n",
      "Step: 98, State history: [ 0.66020952 -0.00619582  1.54811245 -1.16036512 -1.25996114 -0.52931729\n",
      "  1.          0.        ]\n",
      "Step: 99, State history: [ 0.67636931  0.02847977  1.02751373 -1.11682006 -1.38308258 -1.28710222\n",
      "  0.          0.        ]\n",
      "Step: 100, State history: [ 0.68149058 -0.13055392  1.5535137  -1.34084629 -1.29977262 -1.09344935\n",
      "  0.          0.        ]\n",
      "Step: 101, State history: [ 0.64690039 -0.1022648   1.35471353 -1.20535191 -1.47733024 -0.45112556\n",
      "  0.          0.        ]\n",
      "Step: 102, State history: [ 0.6693485  -0.00283259  1.1158268  -1.08324023 -1.45135591 -0.86765931\n",
      "  0.          0.        ]\n",
      "Step: 103, State history: [ 0.65335598  0.03166765  1.64441708 -1.26887141 -1.61282423 -1.17411848\n",
      "  0.          0.        ]\n",
      "Step: 104, State history: [ 0.71370057  0.0537539   1.38917172 -1.34427826 -1.629525   -0.60040906\n",
      "  0.          0.        ]\n",
      "Step: 105, State history: [ 0.71203451 -0.06995009  1.19130831 -1.22456368 -1.64188328 -0.50325005\n",
      "  0.          0.        ]\n",
      "Step: 106, State history: [ 0.69418041  0.0263484   1.21492469 -1.27289077 -1.58979478 -0.92873686\n",
      "  0.          0.        ]\n",
      "Step: 107, State history: [ 0.72525149 -0.03124544  1.18750709 -1.19683857 -1.49916197 -0.66647729\n",
      "  0.          0.        ]\n",
      "Step: 108, State history: [ 0.73082506 -0.02963191  1.19449217 -1.38404113 -1.6421284  -1.05212265\n",
      "  0.          0.        ]\n",
      "Step: 109, State history: [ 0.74215804 -0.10806762  1.4773878  -1.32176989 -1.76264074 -1.14268675\n",
      "  0.          0.        ]\n",
      "Step: 110, State history: [ 0.76411294 -0.06204723  1.32689664 -1.60407359 -1.78428019 -0.5954724\n",
      "  0.          0.        ]\n",
      "Step: 111, State history: [ 0.73261119 -0.11752876  1.41708251 -1.23057098 -1.66000142 -0.52068163\n",
      "  1.          0.        ]\n",
      "Step: 112, State history: [ 0.72195801 -0.11181774  1.17785021 -1.24876165 -1.88769732 -1.21015612\n",
      "  1.          0.        ]\n",
      "Step: 113, State history: [ 0.77705888 -0.12240497  1.38015758 -1.02123521 -1.77020198 -0.68709634\n",
      "  1.          0.        ]\n",
      "Step: 114, State history: [ 0.77881023 -0.35211691  1.36656305 -0.94356381 -1.78062622 -0.27889082\n",
      "  1.          0.        ]\n",
      "Step: 115, State history: [ 0.75721597 -0.27360702  1.51734377 -0.89028689 -1.77794693 -0.14998618\n",
      "  1.          0.        ]\n",
      "Step: 116, State history: [ 0.77056741 -0.10809931  1.57154831 -0.86539829 -1.77652626 -0.29714057\n",
      "  1.          0.        ]\n",
      "Step: 117, State history: [ 0.74935454 -0.40443254  1.61517785 -0.84795648 -1.84166519 -0.27101173\n",
      "  1.          0.        ]\n",
      "Step: 118, State history: [ 0.74382162 -0.06683213  1.6922203  -0.88917901 -1.70617498 -0.49604117\n",
      "  1.          0.        ]\n",
      "Step: 119, State history: [ 0.77845279 -0.24522332  1.52626657 -0.60932034 -1.48594124  0.10940598\n",
      "  1.          0.        ]\n",
      "Step: 120, State history: [ 0.71408075 -0.40648443  1.34009654 -1.0457915  -1.6839797  -0.20314457\n",
      "  1.          0.        ]\n",
      "Step: 121, State history: [ 0.82291696 -0.31691544  1.15968589 -0.21793683 -1.6745458   0.05027924\n",
      "  1.          0.        ]\n",
      "Step: 122, State history: [ 0.83348425 -0.31648995  1.38957225 -0.27551808 -1.69227921  0.58840764\n",
      "  1.          0.        ]\n",
      "Step: 123, State history: [ 0.79148291 -0.31830767  1.74278972 -0.3569402  -1.48531029  0.57603352\n",
      "  1.          0.        ]\n",
      "Step: 124, State history: [ 0.83106213 -0.18399078  1.58328833 -0.51217004 -1.41086245  0.20115954\n",
      "  1.          0.        ]\n",
      "Step: 125, State history: [ 0.8247884  -0.26229491  1.6392939  -0.31426121 -1.30489364  0.40766368\n",
      "  1.          0.        ]\n",
      "Step: 126, State history: [ 0.86961473 -0.28616132  1.2533542  -0.15459538 -1.28924572  0.85647948\n",
      "  1.          0.        ]\n",
      "Step: 127, State history: [ 0.88130057 -0.0985376   1.44267473 -0.24394591 -1.20483546  0.39594257\n",
      "  1.          0.        ]\n",
      "Step: 128, State history: [ 0.92247652 -0.14274718  1.49921354 -0.22613535 -1.18556204  0.36036496\n",
      "  1.          0.        ]\n",
      "Step: 129, State history: [ 0.96424577 -0.34865174  1.18102156  0.06565999 -1.14465898  0.66822256\n",
      "  1.          0.        ]\n",
      "Step: 130, State history: [ 0.88171444 -0.27486801  1.28943967 -0.00759196 -1.36114077  0.76698155\n",
      "  1.          0.        ]\n",
      "Step: 131, State history: [ 0.95091947 -0.15600268  1.19607796 -0.21044223 -1.05532423  0.77627406\n",
      "  1.          0.        ]\n",
      "Step: 132, State history: [ 1.00187595 -0.62589864  1.38478871  0.00428031 -0.69390018  0.66991996\n",
      "  1.          0.        ]\n",
      "Step: 133, State history: [ 0.97484944 -0.35458205  1.14705571  0.01068373 -0.90524982  0.54199042\n",
      "  1.          0.        ]\n",
      "Step: 134, State history: [ 1.01537422 -0.15739542  1.24652803 -0.11601906 -0.90929122  0.19119118\n",
      "  1.          0.        ]\n",
      "Step: 135, State history: [ 1.01547339 -0.30560168  1.27882325  0.05744001 -1.04412916  0.07623547\n",
      "  1.          0.        ]\n",
      "Step: 136, State history: [ 0.98319216 -0.24164641  1.25908268  0.37831182 -1.0368943   0.17313053\n",
      "  1.          0.        ]\n",
      "Step: 137, State history: [ 0.91871017 -0.40054385  1.04789489 -0.14744485 -0.65390631  0.56359141\n",
      "  1.          0.        ]\n",
      "Step: 138, State history: [ 1.01624117 -0.10577092  1.38709482  0.2965666  -0.92918771  0.21609714\n",
      "  1.          0.        ]\n",
      "Step: 139, State history: [ 1.04849216 -0.42692735  1.25177709  0.44366141 -0.86570691  0.33689045\n",
      "  1.          0.        ]\n",
      "Step: 140, State history: [ 1.02544113  0.04466499  1.34168466  0.14402717 -0.9635123  -0.36538336\n",
      "  1.          0.        ]\n",
      "Step: 141, State history: [ 1.01989837 -0.17899617  1.17496909  0.17044191 -0.64795246  0.10093475\n",
      "  1.          0.        ]\n",
      "Step: 142, State history: [ 0.91535055 -0.35714914  1.24793526 -0.05604117 -0.78101692  0.32144432\n",
      "  1.          0.        ]\n",
      "Step: 143, State history: [ 0.98739537 -0.1455376   1.33158611  0.18831587 -0.91433945 -0.26441873\n",
      "  1.          0.        ]\n",
      "Step: 144, State history: [ 0.92617571 -0.33414744  0.90613748 -0.011082   -1.00983458  0.25200631\n",
      "  1.          0.        ]\n",
      "Step: 145, State history: [ 1.01920789 -0.18137916  1.33306022 -0.02691626 -0.9767213   0.28998826\n",
      "  1.          0.        ]\n",
      "Step: 146, State history: [ 0.95855667 -0.39384413  0.86489392  0.13778916 -0.8306924   0.26694416\n",
      "  1.          0.        ]\n",
      "Step: 147, State history: [ 0.96861982 -0.00602572  1.27421255  0.05469682 -0.78796755 -0.07468948\n",
      "  1.          0.        ]\n",
      "Step: 148, State history: [ 0.99418875 -0.28877316  0.93274015  0.16519578 -1.08366371  0.12546747\n",
      "  0.          0.        ]\n",
      "Step: 149, State history: [ 0.96431515 -0.06101402  1.266814   -0.08200984 -0.91341861 -0.06651439\n",
      "  1.          0.        ]\n",
      "Step: 150, State history: [ 0.95996896 -0.41976445  1.0539199  -0.03776413 -1.00130322  0.14062094\n",
      "  1.          0.        ]\n",
      "Step: 151, State history: [ 0.93074088 -0.26619261  1.02962608 -0.17692081 -0.9498414   0.21820538\n",
      "  1.          0.        ]\n",
      "Step: 152, State history: [ 0.89646308 -0.30459588  0.96784527 -0.14236664 -1.04907406  0.56737968\n",
      "  1.          0.        ]\n",
      "Step: 153, State history: [ 0.95497248 -0.13220385  1.03021995  0.29331572 -1.04684936  0.44106754\n",
      "  1.          0.        ]\n",
      "Step: 154, State history: [ 0.95269785 -0.34872146  1.3410361   0.23664873 -0.45435704  0.11105627\n",
      "  1.          0.        ]\n",
      "Step: 155, State history: [ 0.88690638 -0.3670068   1.20506232 -0.12664479 -0.9345833   0.69315441\n",
      "  1.          0.        ]\n",
      "Step: 156, State history: [ 0.91736931 -0.37500655  0.71922675 -0.08508642 -0.97428443  0.71117156\n",
      "  1.          0.        ]\n",
      "Step: 157, State history: [ 0.98840266 -0.31021475  1.05572475  0.06850258 -0.61408432  0.58564228\n",
      "  1.          0.        ]\n",
      "Step: 158, State history: [ 0.94593623 -0.10956032  1.08339194  0.00759637 -0.9606032   0.27029072\n",
      "  1.          0.        ]\n",
      "Step: 159, State history: [ 0.91666524 -0.29374185  0.7028159  -0.17742379 -0.46977688  0.64608526\n",
      "  1.          0.        ]\n",
      "Step: 160, State history: [ 0.94735915 -0.26665709  0.97825049  0.07379227 -0.74469292  0.29631698\n",
      "  1.          0.        ]\n",
      "Step: 161, State history: [ 0.94203594 -0.51023363  0.90631541 -0.02956647 -0.46565064  0.73047316\n",
      "  1.          0.        ]\n",
      "Step: 162, State history: [ 0.97248492  0.00747328  0.530444    0.03264124 -0.70886512  0.11768862\n",
      "  1.          0.        ]\n",
      "Step: 163, State history: [ 1.0046728  -0.26282574  1.13939993  0.31559451 -0.83540613  0.22762953\n",
      "  1.          0.        ]\n",
      "Step: 164, State history: [ 0.95683389 -0.13511236  0.97668577  0.18897063 -0.63974579 -0.16772724\n",
      "  1.          0.        ]\n",
      "Step: 165, State history: [ 0.99487512 -0.0582271   1.12558128  0.01235813 -0.3073282  -0.25196001\n",
      "  1.          0.        ]\n",
      "Step: 166, State history: [ 0.95774366 -0.05358609  1.22698936  0.45293912 -0.7376201  -0.56423199\n",
      "  1.          0.        ]\n",
      "Step: 167, State history: [ 0.90642293 -0.26432176  1.26608625  0.50625572 -0.77498713 -0.40002591\n",
      "  1.          0.        ]\n",
      "Step: 168, State history: [ 0.96058647  0.12414746  0.84250691  0.36934318 -0.73084776 -0.19319679\n",
      "  1.          0.        ]\n",
      "Step: 169, State history: [ 0.91033923 -0.27747684  1.08861682  0.28150412 -0.73933468  0.30768144\n",
      "  1.          0.        ]\n",
      "Step: 170, State history: [ 0.90843983 -0.22578363  0.8008244   0.02962213 -0.65479101  0.07723212\n",
      "  1.          0.        ]\n",
      "Step: 171, State history: [ 0.92517718  0.21159192  1.27292021  0.21845222 -0.54122575 -0.30722339\n",
      "  1.          0.        ]\n",
      "Step: 172, State history: [ 0.96860317  0.17386897  1.11688993  0.29261707 -0.70155982 -0.20888078\n",
      "  1.          0.        ]\n",
      "Step: 173, State history: [ 0.91635762 -0.03524102  1.032085    0.25609621 -0.98159351 -0.15019074\n",
      "  0.          0.        ]\n",
      "Step: 174, State history: [ 0.91355533 -0.03275125  1.20709199  0.17394746 -0.78101683  0.14903339\n",
      "  0.          0.        ]\n",
      "Step: 175, State history: [ 0.90802121  0.19365052  1.18164952  0.31099802 -0.87790627 -0.31845478\n",
      "  0.          0.        ]\n",
      "Step: 176, State history: [ 0.94440042  0.2845269   1.27349315  0.11056839 -0.8128464  -0.4843305\n",
      "  0.          0.        ]\n",
      "Step: 177, State history: [ 0.95512654  0.36613612  1.46207318 -0.13896291 -1.01367204 -0.58901428\n",
      "  0.          0.        ]\n",
      "Step: 178, State history: [ 0.89443426  0.21048355  1.46686075 -0.043746   -0.86722945 -0.06132477\n",
      "  0.          0.        ]\n",
      "Step: 179, State history: [ 0.85170868 -0.06665312  1.47915633 -0.15878545 -1.03377744 -0.33053331\n",
      "  0.          0.        ]\n",
      "Step: 180, State history: [ 0.91849292  0.16176197  1.57443979 -0.21344529 -0.87799297  0.01402343\n",
      "  0.          0.        ]\n",
      "Step: 181, State history: [ 0.86561715  0.31067513  1.28446217 -0.40022216 -0.99956288 -0.1965938\n",
      "  0.          0.        ]\n",
      "Step: 182, State history: [ 0.94221433  0.4753986   1.44845415 -0.39440834 -1.01810452  0.13076045\n",
      "  0.          0.        ]\n",
      "Step: 183, State history: [ 0.93388669  0.36901424  1.05773232 -0.39516789 -1.02691259  0.28212125\n",
      "  0.          0.        ]\n",
      "Step: 184, State history: [ 0.93620299  0.42791423  1.23127327 -0.52595721 -1.00728693  0.3732339\n",
      "  0.          0.        ]\n",
      "Step: 185, State history: [ 0.8912217   0.26734022  1.65403879 -0.54083751 -0.98899442  0.0768445\n",
      "  0.          0.        ]\n",
      "Step: 186, State history: [ 0.8804489   0.18969606  1.82435752 -0.80446385 -0.95837144  0.1268262\n",
      "  0.          0.        ]\n",
      "Step: 187, State history: [ 0.91380922  0.34717103  1.23021678 -0.94000182 -1.07966594  0.2190752\n",
      "  0.          0.        ]\n",
      "Step: 188, State history: [ 0.94597716  0.44235868  1.66762106 -0.77200261 -1.08997958  0.3006085\n",
      "  0.          0.        ]\n",
      "Step: 189, State history: [ 0.98374342  0.40922916  1.20584399 -0.68652562 -1.10967863  0.3431926\n",
      "  0.          0.        ]\n",
      "Step: 190, State history: [ 0.95328814  0.34294232  1.37772298 -0.85508629 -1.1372349   0.47602578\n",
      "  0.          0.        ]\n",
      "Step: 191, State history: [ 0.97059365  0.23110117  1.11692876 -0.88269641 -0.93085245  0.1868504\n",
      "  0.          0.        ]\n",
      "Step: 192, State history: [ 0.9673161   0.27939565  1.32636311 -0.89027106 -0.88589235  0.43292669\n",
      "  0.          0.        ]\n",
      "Step: 193, State history: [ 1.00479608  0.33546178  1.31304431 -0.84853247 -0.90546775  0.47317935\n",
      "  0.          0.        ]\n",
      "Step: 194, State history: [ 0.99515732  0.23437571  1.36445282 -0.94076848 -0.66282302  0.54306866\n",
      "  1.          0.        ]\n",
      "Step: 195, State history: [ 1.05308147  0.12018426  1.09071781 -0.81070075 -0.70153809  0.09205798\n",
      "  0.          0.        ]\n",
      "Step: 196, State history: [ 1.00209791  0.02769321  1.51629898 -1.05854054 -0.83174932  0.31855409\n",
      "  0.          0.        ]\n",
      "Step: 197, State history: [ 0.93422297 -0.06489727  1.28785109 -0.96520058 -0.73778679  0.45439435\n",
      "  0.          0.        ]\n",
      "Step: 198, State history: [ 0.99143174  0.18133523  1.56854065 -1.03115958 -0.60770082  0.40190096\n",
      "  0.          0.        ]\n",
      "Step: 199, State history: [ 0.97312193 -0.13844622  1.34782442 -1.02170688 -0.6753371   0.06436904\n",
      "  0.          0.        ]\n",
      "Step: 200, State history: [ 0.98892516  0.06311956  1.48364573 -1.13297891 -0.5943373   0.44304103\n",
      "  0.          0.        ]\n",
      "Step: 201, State history: [ 1.00459241  0.01158445  1.37503789 -0.85683011 -0.55038961  0.24749116\n",
      "  0.          0.        ]\n",
      "Step: 202, State history: [ 1.046068    0.008767    1.58181874 -1.06719377 -0.24621203  0.41922378\n",
      "  1.          0.        ]\n",
      "Step: 203, State history: [ 1.01110594 -0.23078192  0.87911136 -0.70074007 -0.63850376 -0.21145911\n",
      "  1.          0.        ]\n",
      "Step: 204, State history: [ 1.01289927 -0.30155318  1.28805442 -0.79377183 -0.48901887 -0.15316994\n",
      "  1.          0.        ]\n",
      "Step: 205, State history: [ 0.98882029 -0.32301944  1.2883184  -0.69437974 -0.5644685   0.0689538\n",
      "  1.          0.        ]\n",
      "Step: 206, State history: [ 0.97642275 -0.12988567  1.08615242 -0.77534606 -0.52019627 -0.10311315\n",
      "  1.          0.        ]\n",
      "Step: 207, State history: [ 1.01175597  0.03480618  1.37426918 -0.48807953 -0.74487597 -0.810616\n",
      "  1.          0.        ]\n",
      "Step: 208, State history: [ 0.98074351 -0.01779805  1.734205   -0.50675307 -0.96389221 -0.83174431\n",
      "  1.          0.        ]\n",
      "Step: 209, State history: [ 1.01064002  0.04557627  1.79847007 -0.28958532 -0.82094791 -0.55113414\n",
      "  1.          0.        ]\n",
      "Step: 210, State history: [ 0.96148873 -0.49350709  1.43476348 -0.24410794 -0.93715853 -1.01317882\n",
      "  1.          0.        ]\n",
      "Step: 211, State history: [ 0.9895668  -0.34986013  1.33846794 -0.50266112 -1.0980955  -0.65612673\n",
      "  1.          0.        ]\n",
      "Step: 212, State history: [ 0.91384006 -0.17466488  1.7069512  -0.2484546  -1.17485556 -1.69161155\n",
      "  1.          0.        ]\n",
      "Step: 213, State history: [ 0.94190391 -0.27830101  1.81537709 -0.41691697 -1.37279342 -1.81578981\n",
      "  1.          0.        ]\n",
      "Step: 214, State history: [ 0.98528507 -0.09324983  1.68353595 -0.14859742 -1.15723864 -1.17788451\n",
      "  1.          0.        ]\n",
      "Step: 215, State history: [ 0.94333805 -0.24433086  1.97618188 -0.22351155 -1.41079001 -1.60044326\n",
      "  1.          0.        ]\n",
      "Step: 216, State history: [ 0.87999283 -0.44955822  1.48306801 -0.13362397 -1.77644081 -1.63888512\n",
      "  0.          0.        ]\n",
      "Step: 217, State history: [ 0.95026264  0.08773326  1.96117506 -0.05721186 -1.60271175 -0.67726687\n",
      "  1.          0.        ]\n",
      "Step: 218, State history: [ 0.89674328 -0.07022061  1.47885972 -0.06313156 -1.82832606 -1.55257476\n",
      "  0.          0.        ]\n",
      "Step: 219, State history: [ 0.89560486  0.23192696  1.38882181 -0.45138171 -1.41044611 -1.1131377\n",
      "  0.          0.        ]\n",
      "Step: 220, State history: [ 0.86839495 -0.27941092  1.41218205 -0.51435353 -1.74477179 -0.81257503\n",
      "  0.          0.        ]\n",
      "Step: 221, State history: [ 0.82930801 -0.18138882  1.52303187 -1.03279896 -1.66447588 -1.76066517\n",
      "  0.          0.        ]\n",
      "Step: 222, State history: [ 0.90165458  0.12273536  1.39497574 -0.84731166 -1.91832741 -2.0701563\n",
      "  0.          0.        ]\n",
      "-881.2980773957531\n"
     ]
    }
   ],
   "source": [
    "obs, _ = sim_env.reset()\n",
    "total_reward = 0\n",
    "for _ in range(200):\n",
    "    action = sim_env.action_space.sample()\n",
    "    obs, reward, done, done, info = sim_env.step(action)\n",
    "    total_reward += reward\n",
    "    sim_env.render(\"human\")\n",
    "    if done:\n",
    "        break\n",
    "sim_env.close()\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 145       |\n",
      "|    ep_rew_mean     | -1.24e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 184       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 11        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 151           |\n",
      "|    ep_rew_mean          | -8.2e+06      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 183           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7193775e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.66e+09      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000292     |\n",
      "|    value_loss           | 3.85e+09      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-184.46 +/- 108.20\n",
      "Episode length: 98.14 +/- 19.37\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 98.1          |\n",
      "|    mean_reward          | -184          |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 5000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6426202e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.32e+14      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -1.04e-05     |\n",
      "|    value_loss           | 9.3e+13       |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 152       |\n",
      "|    ep_rew_mean     | -1.74e+07 |\n",
      "| time/              |           |\n",
      "|    fps             | 176       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 34        |\n",
      "|    total_timesteps | 6144      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 151          |\n",
      "|    ep_rew_mean          | -1.3e+07     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 170          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.313226e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.82e+14     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -4.21e-06    |\n",
      "|    value_loss           | 4.84e+14     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Train the model and use the evaluation callback to save the best model.\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:336\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:275\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Optimization step\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 275\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    277\u001b[0m th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import gymnasium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "# Monkey-patch gym to include a __version__ attribute if it's missing.\n",
    "\n",
    "# Set up log folder for monitoring\n",
    "log_dir = \"./logs_dir/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create the training environment and wrap it with a Monitor to log rewards.\n",
    "train_env = sim_env\n",
    "train_env = Monitor(train_env, log_dir)\n",
    "\n",
    "# Create a separate evaluation environment.\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "eval_env = Monitor(eval_env, log_dir)\n",
    "\n",
    "# Set up the evaluation callback. This will evaluate the model every 5000 timesteps,\n",
    "# and save the model if it achieves a new best mean reward.\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=os.path.join(log_dir, 'best_model'),\n",
    "    log_path=log_dir,\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=50,\n",
    "    deterministic=False,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "\n",
    "\n",
    "# Train the model and use the evaluation callback to save the best model.\n",
    "model.learn(total_timesteps=300000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = PPO.load(os.path.join(log_dir, 'best_model/best_model.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 14:48:51.615 Python[9586:276873] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-25 14:48:51.615 Python[9586:276873] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -125.62913699720562\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"human\")   \n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "terminated = False\n",
    "total_reward = 0\n",
    "while not (done or terminated):\n",
    "    # Predict the next action using the trained policy.\n",
    "    action, _ = best_model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, terminated ,_ = env.step(action)\n",
    "    total_reward += reward\n",
    "    env.render()\n",
    "\n",
    "env.close()\n",
    "print(f\"Total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -47.27233590475288\n",
      "Total reward: -49.26818347728339\n",
      "Total reward: -31.09010193558929\n",
      "Total reward: 24.62084582662014\n",
      "Total reward: 26.930244123126627\n",
      "Total reward: 20.390678249649582\n",
      "Total reward: 26.231009479917205\n",
      "Total reward: 141.87562290808742\n",
      "Total reward: -21.523899384709907\n",
      "Total reward: 28.71361591344933\n",
      "Total reward: -33.49156277028581\n",
      "Total reward: 14.307746183233292\n",
      "Total reward: 25.068558480531536\n",
      "Total reward: 3.8256308610058056\n",
      "Total reward: -5.88428720794407\n",
      "Total reward: 140.46385962086885\n",
      "Total reward: -41.16876828950086\n",
      "Total reward: -49.145904509079074\n",
      "Total reward: -1.3697761881111603\n",
      "Total reward: 1.4950432277937296\n",
      "Total reward: -33.076456065520006\n",
      "Total reward: -50.51191341061657\n",
      "Total reward: -24.485016168297463\n",
      "Total reward: -56.033083499235254\n",
      "Total reward: -2.7709723496333396\n",
      "Total reward: -21.41303550699675\n",
      "Total reward: 13.71695829171523\n",
      "Total reward: -53.05022353912637\n",
      "Total reward: -67.1398640232491\n",
      "Total reward: -7.322877967328111\n",
      "Total reward: -24.18518285263289\n",
      "Total reward: -87.13008751545266\n",
      "Total reward: -44.45428332606903\n",
      "Total reward: -40.83601993548923\n",
      "Total reward: 6.276198151677619\n",
      "Total reward: -80.24640913856089\n",
      "Total reward: 29.632440770109838\n",
      "Total reward: -43.27458950256138\n",
      "Total reward: -11.712626213486956\n",
      "Total reward: -51.930270135249636\n",
      "Total reward: -90.37402115982269\n",
      "Total reward: -61.15346901025274\n",
      "Total reward: 9.359089949542948\n",
      "Total reward: -32.92163887168314\n",
      "Total reward: 8.592531013811524\n",
      "Total reward: -27.700201403872086\n",
      "Total reward: -26.124474323134308\n",
      "Total reward: 0.04580007801087049\n",
      "Total reward: -16.72685349580081\n",
      "Total reward: -87.23786082029392\n",
      "Total reward: 6.4566971011693965\n",
      "Total reward: -52.61471329576966\n",
      "Total reward: -13.018201411283073\n",
      "Total reward: 44.04756634579033\n",
      "Total reward: -12.2474734262141\n",
      "Total reward: -8.559362880768006\n",
      "Total reward: -2.2333899350939816\n",
      "Total reward: 2.8572256729734136\n",
      "Total reward: -48.92206757600135\n",
      "Total reward: 30.907759250029642\n",
      "Total reward: -8.594653024182662\n",
      "Total reward: -19.27776757355153\n",
      "Total reward: -28.180909793425215\n",
      "Total reward: -51.71133355618444\n",
      "Total reward: -5.533495847934844\n",
      "Total reward: -50.096186960437585\n",
      "Total reward: -8.467060375426058\n",
      "Total reward: -40.75030666035046\n",
      "Total reward: -26.328447524363582\n",
      "Total reward: -32.557330711634975\n",
      "Total reward: 22.899920623566615\n",
      "Total reward: 25.30506034664026\n",
      "Total reward: 4.777345801324088\n",
      "Total reward: 10.007337669254014\n",
      "Total reward: 3.7181975927941835\n",
      "Total reward: -5.145180569175906\n",
      "Total reward: 3.6405322775298714\n",
      "Total reward: -33.94372693510226\n",
      "Total reward: -41.24797452352493\n",
      "Total reward: 19.866390254115487\n",
      "Total reward: -33.30481952982423\n",
      "Total reward: -52.57520919218209\n",
      "Total reward: -58.1566561280429\n",
      "Total reward: -18.405684732085618\n",
      "Total reward: -62.86730845828805\n",
      "Total reward: -2.8788274174865336\n",
      "Total reward: -17.759395777260266\n",
      "Total reward: -86.85226106387043\n",
      "Total reward: -5.063111534498546\n",
      "Total reward: -9.469007072081894\n",
      "Total reward: 29.262503488857305\n",
      "Total reward: 4.238970181468346\n",
      "Total reward: -10.985472303548619\n",
      "Total reward: -21.429118914071296\n",
      "Total reward: -11.660114204784591\n",
      "Total reward: -33.11692246358277\n",
      "Total reward: -66.0844371098464\n",
      "Total reward: -33.7277466072414\n",
      "Total reward: -26.72846312411707\n",
      "Total reward: -52.08622673906458\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"rgb_array\")  \n",
    "all_rewards = []\n",
    "for i in range(100):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    terminated = False\n",
    "    total_reward = 0\n",
    "    while not (done or terminated):\n",
    "        # Predict the next action using the trained policy.\n",
    "        action, _ = best_model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, terminated ,_ = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "    all_rewards.append(total_reward)\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1 model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mall_rewards\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_rewards' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 1 model\n",
    "np.mean(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">No eval environment provided, will not create eval callback</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Creating PPO model</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Training model</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 147       |\n",
      "|    ep_rew_mean     | -2.01e+06 |\n",
      "| time/              |           |\n",
      "|    fps             | 177       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 11        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 161           |\n",
      "|    ep_rew_mean          | -1.2e+06      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 167           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2118835e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.3e+11       |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | 6.9e-06       |\n",
      "|    value_loss           | 1.17e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 165           |\n",
      "|    ep_rew_mean          | -1.07e+07     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 168           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4334801e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -5.11e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.73e+09      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    value_loss           | 6.09e+09      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pi_optimal.planners.online_planner import OnlinePlanner\n",
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=[nn_model, nn_model2, nn_model3], dataset=dataset_train, max_episode_steps=200)\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "\n",
    "online_planner = OnlinePlanner(env=sim_env, eval_env=None, train_params={\"total_timesteps\": 6000}, eval_params={\"n_eval_episodes\": 50, \"eval_freq\": 5000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Inference from a dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details  look in to the predict function of the planer. It takes the last observation and uses it as observation. Ensure that the dataset is set to **is_inference == True** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 5438.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 50 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 1 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Using processors provided in the dataset_configuration.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean 0.11 and std 0.33'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_inf = data_collector.collect(n_steps=50, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "\n",
    "dataset_inf = dataset_test = TimeseriesDataset(\n",
    "    df=df_inf,\n",
    "    dataset_config=dataset_config,\n",
    "    train_processors=False,\n",
    "    is_inference=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_planner.plan(dataset_inf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi-optimal-RKvx2dB5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
