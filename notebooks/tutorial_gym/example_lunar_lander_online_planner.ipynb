{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "Import required libraries including NumPy, sklearn with Intel extension, and pi_optimal utilities. Configure warning suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment and Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "#from sklearnex import patch_sklearn\n",
    "import warnings\n",
    "\n",
    "# Change directory to the parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Apply Intel extension to sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import pi_optimal utilities\n",
    "from pi_optimal.utils.data_generators.gym_data_generator import GymDataGenerator\n",
    "from pi_optimal.datasets.timeseries_dataset import TimeseriesDataset\n",
    "from pi_optimal.models.sklearn.random_forest_model import RandomForest\n",
    "from pi_optimal.models.sklearn.mlp import NeuralNetwork\n",
    "from pi_optimal.evaluators.base_evaluator import BaseEvaluator\n",
    "from pi_optimal.evaluators.plotting import plot_n_step_evaluation, plot_n_step_episode_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gym Data Generator\n",
    "Initialize GymDataGenerator with LunarLander environment and collect training and test data with specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|██████████| 10000/10000 [00:00<00:00, 41759.05it/s]\n",
      "Collecting steps: 100%|██████████| 5000/5000 [00:00<00:00, 47382.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create Gym Data Generator\n",
    "\n",
    "# Initialize GymDataGenerator with LunarLander environment\n",
    "data_collector = GymDataGenerator(env_name=\"LunarLander-v3\")\n",
    "\n",
    "# Collect training data\n",
    "df_train = data_collector.collect(n_steps=10000, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "df_test = data_collector.collect(n_steps=5000, max_steps_per_episode=200, env_seed=None, action_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tutorial_gym/dataset_20250401_160426.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtutorial_gym/dataset_20250401_160426.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tutorial_gym/dataset_20250401_160426.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"tutorial_gym/dataset_20250401_160426.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'episode_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'episode_id'"
     ]
    }
   ],
   "source": [
    "df_train[\"reward\"] = df_train.groupby(\"episode_id\").reward.shift(1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Dataset Parameters\n",
    "Set up dataset configuration dictionary defining features, processors, and evaluation metrics for states, actions, and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Dataset Parameters\n",
    "\n",
    "# Define dataset configuration dictionary\n",
    "dataset_config = {\n",
    "    \"episode_column\": \"episode\",\n",
    "    \"timestep_column\": \"step\",\n",
    "    \"states\": {\n",
    "        0: {\"name\": \"state_0\", \"type\": \"numerical\", \"processor\": {\"name\": \"StandardScaler\"}, \"evaluation_metric\": \"mae\"},\n",
    "        1: {\"name\": \"state_1\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        2: {\"name\": \"state_2\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        3: {\"name\": \"state_3\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        4: {\"name\": \"state_4\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        5: {\"name\": \"state_5\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        6: {\"name\": \"state_6\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        7: {\"name\": \"state_7\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        8: {\"name\": \"done\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        9: {\"name\": \"reward\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "    },\n",
    "    \"actions\": {\n",
    "        0: {\"name\": \"action_0\", \"type\": \"categorial\", \"processor\": {\"name\": \"OneHotEncoder\"}},\n",
    "    },\n",
    "    \"reward_feature_idx\": 9,\n",
    "    \"reward_vector_idx\": 9,\n",
    "    \"reward_column\": \"reward\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Test Datasets\n",
    "Initialize TimeseriesDataset objects with collected data, applying the configuration and setting lookback/forecast windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">⚙️</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Dataset has 10000 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Dataset has 113 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">⚙️</span>\n",
       "                <span class=\"logger-message\">Fitting feature processors...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Processors created and fitted</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">⚙️</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean -0.01 and std 0.29'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✨</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Training and Test Datasets\n",
    "\n",
    "# Define lookback and forecast timesteps\n",
    "LOOKBACK_TIMESTEPS = 10\n",
    "FORECAST_TIMESTEPS = 1\n",
    "\n",
    "# Initialize TimeseriesDataset objects for training and test data\n",
    "dataset_train = TimeseriesDataset(\n",
    "    df=df_train,\n",
    "    dataset_config=dataset_config,\n",
    "    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "    forecast_timesteps=FORECAST_TIMESTEPS,\n",
    "    train_processors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network Model\n",
    "Create and train a Neural Network model with specified hyperparameters on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575995f56ed6439798e53d0590a340aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pi_optimal.models.torch.mlp import NeuralNetworkTorch\n",
    "models = []\n",
    "for i in range(1):\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "    nn_model1 = NeuralNetworkTorch(params={\n",
    "        \"hidden_layer_sizes\": (16, 16),\n",
    "        \"alpha\": 0.01,\n",
    "        \"learning_rate_init\": 0.001}\n",
    "    )\n",
    "        \n",
    "    # Train the Neural Network model on the first training dataset\n",
    "    nn_model1.fit(dataset_train)\n",
    "    models.append(nn_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Workflow\n",
    "\n",
    "Here you could see how it works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=models, dataset=dataset_train, max_episode_steps=200, use_start_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24, State history: [ 0.13584271  1.4454533   0.50406759 -0.04353851 -0.10645362 -0.05044999\n",
      "  0.          0.        ]\n",
      "Step: 25, State history: [ 0.13948215  1.4454533   0.49664563 -0.0505648  -0.11756632 -0.06748867\n",
      "  0.          0.        ]\n",
      "Step: 26, State history: [ 0.14363463  1.4454533   0.48446734 -0.07982541 -0.11896245  0.01715076\n",
      "  0.          0.        ]\n",
      "Step: 27, State history: [ 0.14799994  1.4454533   0.47276958 -0.1063061  -0.10479766  0.04932263\n",
      "  0.          0.        ]\n",
      "Step: 28, State history: [ 0.15311162  1.4454533   0.47790869 -0.12601496 -0.10870639  0.07045847\n",
      "  0.          0.        ]\n",
      "Step: 29, State history: [ 0.15726526  1.4454533   0.47446665 -0.14419209 -0.1022042   0.02351007\n",
      "  0.          0.        ]\n",
      "Step: 30, State history: [ 0.16126725  1.44440108  0.47670515 -0.13536394 -0.10906601 -0.00806893\n",
      "  0.          0.        ]\n",
      "Step: 31, State history: [ 0.16683203  1.44179361  0.4668234  -0.17482216 -0.11482928  0.05028876\n",
      "  0.          0.        ]\n",
      "Step: 32, State history: [ 0.17054235  1.4422194   0.46650759 -0.15599665 -0.11566569  0.03477991\n",
      "  0.          0.        ]\n",
      "Step: 33, State history: [ 0.1751024   1.43744951  0.46940109 -0.18090717 -0.10858216  0.01302696\n",
      "  0.          0.        ]\n",
      "Step: 34, State history: [ 0.17975478  1.43147909  0.46748825 -0.20631313 -0.09815011 -0.00351976\n",
      "  0.          0.        ]\n",
      "Step: 35, State history: [ 0.18405558  1.42512351  0.47242654 -0.19432885 -0.11024437 -0.03899893\n",
      "  0.          0.        ]\n",
      "Step: 36, State history: [ 0.18965408  1.41422475  0.46557347 -0.22252463 -0.09616162 -0.03656287\n",
      "  0.          0.        ]\n",
      "Step: 37, State history: [ 0.19417994  1.41233162  0.47005636 -0.25319896 -0.10047773 -0.02994038\n",
      "  0.          0.        ]\n",
      "Step: 38, State history: [ 0.19858976  1.40655221  0.46674344 -0.27210905 -0.11395417 -0.0383288\n",
      "  0.          0.        ]\n",
      "Step: 39, State history: [ 0.20386088  1.39821801  0.47571457 -0.25130289 -0.11240633 -0.04390712\n",
      "  0.          0.        ]\n",
      "Step: 40, State history: [ 0.20819215  1.39038194  0.46593683 -0.28673491 -0.11018416 -0.05798134\n",
      "  0.          0.        ]\n",
      "Step: 41, State history: [ 0.21215387  1.38460472  0.47405438 -0.31075185 -0.11661569 -0.07305612\n",
      "  0.          0.        ]\n",
      "Step: 42, State history: [ 0.21578246  1.37429226  0.45820137 -0.33482637 -0.11520389 -0.00548406\n",
      "  0.          0.        ]\n",
      "Step: 43, State history: [ 0.22030167  1.3655938   0.45261805 -0.36188772 -0.12152997 -0.01731086\n",
      "  0.          0.        ]\n",
      "Step: 44, State history: [ 0.22464139  1.35696306  0.45048194 -0.38694002 -0.11871845 -0.00995072\n",
      "  0.          0.        ]\n",
      "Step: 45, State history: [ 0.22708533  1.34762892  0.44422224 -0.40746019 -0.12888738  0.01677851\n",
      "  0.          0.        ]\n",
      "Step: 46, State history: [ 0.23258497  1.33497767  0.44538472 -0.38923623 -0.11416348  0.04106316\n",
      "  0.          0.        ]\n",
      "Step: 47, State history: [ 0.23721701  1.33165548  0.45300298 -0.36285692 -0.12130867  0.09679354\n",
      "  0.          0.        ]\n",
      "Step: 48, State history: [ 0.24167131  1.31953034  0.46107543 -0.38444327 -0.11089829  0.10002422\n",
      "  0.          0.        ]\n",
      "Step: 49, State history: [ 0.24422721  1.30779472  0.45870548 -0.40831616 -0.09936125 -0.02791312\n",
      "  0.          0.        ]\n",
      "Step: 50, State history: [ 0.24908881  1.29492109  0.46275962 -0.40088364 -0.11612753 -0.01634262\n",
      "  0.          0.        ]\n",
      "Step: 51, State history: [ 0.25505164  1.2863457   0.4628817  -0.43167566 -0.11249616 -0.01841917\n",
      "  0.          0.        ]\n",
      "Step: 52, State history: [ 0.25859646  1.27646128  0.47538947 -0.41433803 -0.11694088 -0.03280878\n",
      "  0.          0.        ]\n",
      "Step: 53, State history: [ 0.26478254  1.25858358  0.48226189 -0.44445995 -0.1128626  -0.02269922\n",
      "  0.          0.        ]\n",
      "Step: 54, State history: [ 0.2695996   1.24736125  0.49427757 -0.46584291 -0.10780646 -0.10128239\n",
      "  0.          0.        ]\n",
      "Step: 55, State history: [ 0.27427074  1.23176193  0.50225537 -0.45121664 -0.11596526 -0.09621006\n",
      "  0.          0.        ]\n",
      "Step: 56, State history: [ 0.27969292  1.22159294  0.51156389 -0.44132253 -0.11262687 -0.14062383\n",
      "  0.          0.        ]\n",
      "Step: 57, State history: [ 0.28467101  1.21670187  0.51929231 -0.42958431 -0.12142657 -0.11812366\n",
      "  0.          0.        ]\n",
      "Step: 58, State history: [ 0.28990787  1.20628233  0.52926894 -0.45380594 -0.14411964 -0.14412172\n",
      "  0.          0.        ]\n",
      "Step: 59, State history: [ 0.29462008  1.18542021  0.5209827  -0.47514092 -0.13813024 -0.08164084\n",
      "  0.          0.        ]\n",
      "Step: 60, State history: [ 0.30005475  1.17856469  0.53127503 -0.46904339 -0.14845619 -0.13727759\n",
      "  0.          0.        ]\n",
      "Step: 61, State history: [ 0.30638785  1.16714029  0.54544458 -0.45126346 -0.14822056 -0.12587706\n",
      "  0.          0.        ]\n",
      "Step: 62, State history: [ 0.31052219  1.15390803  0.537227   -0.48394159 -0.15586168 -0.07848932\n",
      "  0.          0.        ]\n",
      "Step: 63, State history: [ 0.31642795  1.1440225   0.54476892 -0.46718449 -0.17048606 -0.09151385\n",
      "  0.          0.        ]\n",
      "Step: 64, State history: [ 0.32286225  1.13374832  0.55778799 -0.44349721 -0.18160125 -0.07761228\n",
      "  0.          0.        ]\n",
      "Step: 65, State history: [ 0.32809602  1.11967616  0.5552799  -0.48455263 -0.18425047 -0.02139275\n",
      "  0.          0.        ]\n",
      "Step: 66, State history: [ 0.33281125  1.10934388  0.57053562 -0.52133239 -0.18648938 -0.09511748\n",
      "  0.          0.        ]\n",
      "Step: 67, State history: [ 0.33873645  1.09754431  0.56301296 -0.54877001 -0.19627649 -0.055281\n",
      "  0.          0.        ]\n",
      "Step: 68, State history: [ 0.34484881  1.08271585  0.55827762 -0.58002772 -0.21205864 -0.00905988\n",
      "  0.          0.        ]\n",
      "Step: 69, State history: [ 0.35015889  1.0705658   0.56279153 -0.60368517 -0.20424513 -0.01542641\n",
      "  0.          0.        ]\n",
      "Step: 70, State history: [ 3.55542919e-01  1.05934949e+00  5.77758952e-01 -6.26871343e-01\n",
      " -2.17873362e-01 -7.78694129e-04  0.00000000e+00  0.00000000e+00]\n",
      "Step: 71, State history: [ 0.36168788  1.0424956   0.58818301 -0.65904267 -0.21528982 -0.07077117\n",
      "  0.          0.        ]\n",
      "Step: 72, State history: [ 0.36730337  1.02708031  0.59306551 -0.68700416 -0.22462405 -0.10007789\n",
      "  0.          0.        ]\n",
      "Step: 73, State history: [ 0.37242841  1.01104989  0.58971289 -0.73031497 -0.23515628 -0.03426085\n",
      "  0.          0.        ]\n",
      "Step: 74, State history: [ 0.37763832  0.99823006  0.59384156 -0.75961521 -0.22780802 -0.11354086\n",
      "  0.          0.        ]\n",
      "Step: 75, State history: [ 0.38348031  0.98081523  0.60171115 -0.73996988 -0.24345933 -0.03844773\n",
      "  0.          0.        ]\n",
      "Step: 76, State history: [ 0.38998866  0.96053718  0.60248964 -0.76658018 -0.24177017 -0.04247773\n",
      "  0.          0.        ]\n",
      "Step: 77, State history: [ 0.39492452  0.93841341  0.60384274 -0.79467986 -0.23607191 -0.03609194\n",
      "  0.          0.        ]\n",
      "Step: 78, State history: [ 0.40133664  0.91771662  0.6075732  -0.82569184 -0.23996746 -0.04772346\n",
      "  0.          0.        ]\n",
      "Step: 79, State history: [ 0.4074591   0.90176455  0.61979044 -0.80617236 -0.24267074 -0.02750314\n",
      "  0.          0.        ]\n",
      "Step: 80, State history: [ 0.41438809  0.88394584  0.63075074 -0.79294176 -0.24858834 -0.03005028\n",
      "  0.          0.        ]\n",
      "Step: 81, State history: [ 0.42097213  0.86654599  0.63518614 -0.8237115  -0.25927018 -0.01472179\n",
      "  0.          0.        ]\n",
      "Step: 82, State history: [ 0.42661275  0.84221218  0.65149496 -0.8551425  -0.26890993 -0.0573798\n",
      "  0.          0.        ]\n",
      "Step: 83, State history: [ 0.43389732  0.82041652  0.65588616 -0.88298904 -0.26359558 -0.09862267\n",
      "  0.          0.        ]\n",
      "Step: 84, State history: [ 0.44071612  0.79936152  0.66960554 -0.87276644 -0.27860997 -0.0837703\n",
      "  0.          0.        ]\n",
      "Step: 85, State history: [ 0.44759821  0.77937848  0.66673577 -0.91128817 -0.27203767 -0.02805078\n",
      "  0.          0.        ]\n",
      "Step: 86, State history: [ 0.45315002  0.75636812  0.6627101  -0.9357236  -0.27556199 -0.02820679\n",
      "  0.          0.        ]\n",
      "Step: 87, State history: [ 0.45996979  0.73058955  0.66410646 -0.96164211 -0.28232612 -0.02837766\n",
      "  0.          0.        ]\n",
      "Step: 88, State history: [ 0.46656098  0.71184574  0.68014369 -0.93900145 -0.28247384 -0.00173906\n",
      "  0.          0.        ]\n",
      "Step: 89, State history: [ 0.47414724  0.68987045  0.69552247 -0.96844812 -0.27711521 -0.02783425\n",
      "  0.          0.        ]\n",
      "Step: 90, State history: [ 0.48051561  0.67397255  0.71019301 -0.95900353 -0.28562316 -0.05186588\n",
      "  0.          0.        ]\n",
      "Step: 91, State history: [ 0.4873392   0.64465793  0.70299663 -0.99438364 -0.29573855 -0.01714781\n",
      "  0.          0.        ]\n",
      "Step: 92, State history: [ 4.94513505e-01  6.26693532e-01  7.10930860e-01 -1.03126407e+00\n",
      " -3.01821106e-01 -3.45255367e-04  0.00000000e+00  0.00000000e+00]\n",
      "Step: 93, State history: [ 0.50016718  0.59864527  0.70886881 -1.05159077 -0.30497248  0.00665643\n",
      "  0.          0.        ]\n",
      "Step: 94, State history: [ 0.5076553   0.57722417  0.71671596 -1.04009619 -0.30211105  0.00110915\n",
      "  0.          0.        ]\n",
      "Step: 95, State history: [ 0.51493441  0.5559827   0.72846489 -1.0178206  -0.29322458  0.05131811\n",
      "  0.          0.        ]\n",
      "Step: 96, State history: [ 0.52237854  0.53369908  0.74545183 -1.00778806 -0.29447532  0.01182544\n",
      "  0.          0.        ]\n",
      "Step: 97, State history: [ 0.52859274  0.50314034  0.74249408 -1.03641413 -0.28835893  0.07900854\n",
      "  0.          0.        ]\n",
      "Step: 98, State history: [ 0.53526794  0.4855162   0.75437151 -1.07504905 -0.2958379  -0.01793798\n",
      "  0.          0.        ]\n",
      "Step: 99, State history: [ 0.54266135  0.46192351  0.75346351 -1.09662009 -0.30096242 -0.00639744\n",
      "  0.          0.        ]\n",
      "Step: 100, State history: [ 0.5485753   0.43620466  0.74751354 -1.14040912 -0.30990059  0.04129183\n",
      "  0.          0.        ]\n",
      "Step: 101, State history: [ 0.55689351  0.41650784  0.76552012 -1.12951047 -0.30229841  0.09669912\n",
      "  0.          0.        ]\n",
      "Step: 102, State history: [ 0.56287638  0.38940487  0.76022755 -1.14227784 -0.30354824  0.07676546\n",
      "  0.          0.        ]\n",
      "Step: 103, State history: [ 0.56957787  0.35902297  0.75588652 -1.17379275 -0.29486504  0.24116732\n",
      "  0.          0.        ]\n",
      "Step: 104, State history: [ 0.57583244  0.33963473  0.76999031 -1.15381488 -0.28037189  0.10351634\n",
      "  0.          0.        ]\n",
      "Step: 105, State history: [ 0.58246084  0.31620428  0.76295696 -1.18421201 -0.28154225  0.18799816\n",
      "  0.          0.        ]\n",
      "Step: 106, State history: [ 0.58890976  0.29459174  0.78028888 -1.22547573 -0.27570203  0.14261095\n",
      "  0.          0.        ]\n",
      "Step: 107, State history: [ 0.59596436  0.27075413  0.79076138 -1.19925157 -0.27067662  0.07868219\n",
      "  0.          0.        ]\n",
      "Step: 108, State history: [ 0.60412311  0.24637592  0.79866393 -1.20285148 -0.28819297  0.13564132\n",
      "  0.          0.        ]\n",
      "Step: 109, State history: [ 0.61093059  0.21893788  0.79813343 -1.21482505 -0.26757652  0.13636415\n",
      "  0.          0.        ]\n",
      "Step: 110, State history: [ 0.61648629  0.19282316  0.79227895 -1.22212258 -0.26381777  0.08492082\n",
      "  0.          0.        ]\n",
      "Step: 111, State history: [ 0.62324913  0.1645507   0.7820423  -1.2356607  -0.26330797  0.16349171\n",
      "  0.          0.        ]\n",
      "Step: 112, State history: [ 0.62980629  0.14610224  0.79878442 -1.26271593 -0.25690154  0.1266758\n",
      "  0.          0.        ]\n",
      "Step: 113, State history: [ 0.63599642  0.12081626  0.79455275 -1.24471113 -0.24132804  0.14048802\n",
      "  0.          0.        ]\n",
      "Step: 114, State history: [ 0.64202894  0.09777131  0.80364331 -1.2682594  -0.24710673  0.12430688\n",
      "  0.          0.        ]\n",
      "Step: 115, State history: [ 0.64800834  0.07786709  0.79431689 -1.23979332 -0.2347465   0.19576958\n",
      "  0.          0.        ]\n",
      "Step: 116, State history: [ 0.65345579  0.06148843  0.79917695 -1.213511   -0.24254566  0.19488425\n",
      "  0.          0.        ]\n",
      "Step: 117, State history: [ 0.6593595   0.04291543  0.79999604 -1.17284742 -0.21936488  0.33998391\n",
      "  0.          0.        ]\n",
      "Step: 118, State history: [ 0.66349019  0.02543485  0.78876314 -1.19547243 -0.19707447  0.39195037\n",
      "  0.          0.        ]\n",
      "Step: 119, State history: [ 6.68492362e-01  5.52283983e-04  7.78849200e-01 -1.22079571e+00\n",
      " -1.71052535e-01  4.60481181e-01  0.00000000e+00  0.00000000e+00]\n",
      "Step: 120, State history: [ 0.6734912  -0.01892865  0.78741059 -1.21293884 -0.145442    0.38279384\n",
      "  0.          0.        ]\n",
      "Step: 121, State history: [ 0.68055281 -0.03705299  0.79251336 -1.19751406 -0.12375223  0.40010481\n",
      "  0.          0.        ]\n",
      "Step: 122, State history: [ 0.68623579 -0.05595002  0.80316626 -1.22007037 -0.11087988  0.41487134\n",
      "  0.          0.        ]\n",
      "Step: 123, State history: [ 0.6923644  -0.07761545  0.79994153 -1.23132003 -0.08406732  0.30574989\n",
      "  0.          0.        ]\n",
      "Step: 124, State history: [ 0.69792726 -0.10246763  0.79187717 -1.25211099 -0.09675698  0.35486574\n",
      "  0.          0.        ]\n",
      "Step: 125, State history: [ 0.7047371  -0.12086769  0.79290077 -1.27241677 -0.06746235  0.32506238\n",
      "  0.          0.        ]\n",
      "Step: 126, State history: [ 0.70987307 -0.13527588  0.80418751 -1.29097615 -0.0645352   0.26430203\n",
      "  0.          0.        ]\n",
      "Step: 127, State history: [ 0.71600612 -0.15404117  0.80789141 -1.29407269 -0.05203566  0.29679806\n",
      "  0.          0.        ]\n",
      "Step: 128, State history: [ 0.72148628 -0.17201184  0.8050106  -1.26455093 -0.03526095  0.22837266\n",
      "  0.          0.        ]\n",
      "Step: 129, State history: [ 0.72632792 -0.19024042  0.80126317 -1.26010941 -0.03423873  0.21183047\n",
      "  0.          0.        ]\n",
      "Step: 130, State history: [ 0.73083564 -0.20440972  0.7976351  -1.27443099 -0.02120464  0.21573151\n",
      "  0.          0.        ]\n",
      "Step: 131, State history: [ 0.73561187 -0.21540586  0.79590428 -1.24170755 -0.02222385  0.24246345\n",
      "  0.          0.        ]\n",
      "Step: 132, State history: [ 0.74155835 -0.22792244  0.79128871 -1.25097455 -0.01769971  0.31942431\n",
      "  0.          0.        ]\n",
      "Step: 133, State history: [ 0.74538748 -0.24158068  0.80035678 -1.24145931 -0.00284418  0.34601788\n",
      "  0.          0.        ]\n",
      "Step: 134, State history: [ 0.75083813 -0.2618226   0.80090131 -1.27319672  0.01486784  0.26356641\n",
      "  0.          0.        ]\n",
      "Step: 135, State history: [ 0.7554907  -0.27797961  0.80029553 -1.28414591  0.0148206   0.21053289\n",
      "  0.          0.        ]\n",
      "Step: 136, State history: [ 0.76043246 -0.29245231  0.79735643 -1.30020397  0.00552613  0.12719287\n",
      "  0.          0.        ]\n",
      "Step: 137, State history: [ 0.76637012 -0.30646473  0.79259621 -1.29680046 -0.00249266  0.24200584\n",
      "  0.          0.        ]\n",
      "Step: 138, State history: [ 0.77180195 -0.32133321  0.7883858  -1.30245688  0.00602874  0.22974834\n",
      "  0.          0.        ]\n",
      "Step: 139, State history: [ 0.77570066 -0.33562985  0.78284942 -1.29827364  0.00167277  0.49600062\n",
      "  0.          0.        ]\n",
      "Step: 140, State history: [ 0.78098203 -0.35132316  0.78734562 -1.27586458  0.03884531  0.39142595\n",
      "  0.          0.        ]\n",
      "Step: 141, State history: [ 0.78562918 -0.36027743  0.7860521  -1.28941544  0.03848888  0.43810165\n",
      "  0.          0.        ]\n",
      "Step: 142, State history: [ 0.78934923 -0.37521586  0.78457628 -1.30333359  0.04407874  0.42671602\n",
      "  0.          0.        ]\n",
      "Step: 143, State history: [ 0.79435091 -0.38630929  0.7972154  -1.35358357  0.05486509  0.45257489\n",
      "  0.          0.        ]\n",
      "Step: 144, State history: [ 0.80024865 -0.40085517  0.80173571 -1.32230596  0.06727247  0.31522863\n",
      "  0.          0.        ]\n",
      "Step: 145, State history: [ 0.8056409  -0.41936985  0.79189761 -1.34123932  0.06087886  0.34388462\n",
      "  0.          0.        ]\n",
      "Step: 146, State history: [ 0.80925777 -0.43575471  0.7826811  -1.3331191   0.0709354   0.33728816\n",
      "  0.          0.        ]\n",
      "Step: 147, State history: [ 0.81504456 -0.44882123  0.79358444 -1.33896197  0.07519774  0.29059669\n",
      "  0.          0.        ]\n",
      "Step: 148, State history: [ 0.81939411 -0.46417124  0.78613684 -1.29997022  0.07816617  0.31166918\n",
      "  1.          0.        ]\n",
      "Step: 149, State history: [ 0.82147355 -0.4836773   0.71067463 -1.09153067  0.08180331  2.92583923\n",
      "  1.          0.        ]\n",
      "Step: 150, State history: [ 0.82429733 -0.49965705  0.63370865 -0.94653787  0.37645751  4.54840787\n",
      "  1.          0.        ]\n",
      "Step: 151, State history: [ 0.82474401 -0.52761871  0.5697422  -0.63571887  0.65391773  4.1246353\n",
      "  1.          1.        ]\n",
      "Step: 152, State history: [ 0.82193223 -0.57068334  0.46145171 -0.51012467  0.74341736  4.67477166\n",
      "  1.          1.        ]\n",
      "Step: 153, State history: [ 0.81914393 -0.59772985  0.35064296 -0.35671535  0.86213021  4.62408326\n",
      "  0.          1.        ]\n",
      "Step: 154, State history: [ 0.81826614 -0.6119584   0.32233802 -0.35978319  0.97105645  3.18867942\n",
      "  0.          1.        ]\n",
      "Step: 155, State history: [ 0.81848284 -0.63547723  0.28985754 -0.47367624  0.99548731  1.16641104\n",
      "  0.          1.        ]\n",
      "Step: 156, State history: [ 0.81866483 -0.64285264  0.26445472 -0.63257727  0.91729372 -1.37874598\n",
      "  0.          1.        ]\n",
      "Step: 157, State history: [ 0.82265887 -0.650234    0.30057708 -0.56574766  0.77143935 -3.77229018\n",
      "  0.          1.        ]\n",
      "Step: 158, State history: [ 0.82489024 -0.65455357  0.39636874 -0.54458979  0.46691312 -4.76591024\n",
      "  1.          0.        ]\n",
      "Step: 159, State history: [ 0.83317765 -0.63261682  0.50000502 -0.46758861  0.08960722 -3.2651578\n",
      "  1.          0.        ]\n",
      "Step: 160, State history: [ 0.83950922 -0.6120163   0.62006382 -0.49562362 -0.09863017 -1.86749976\n",
      "  0.          0.        ]\n",
      "Step: 161, State history: [ 0.84874193 -0.59337887  0.82203707 -0.67447427 -0.22132387 -1.28417809\n",
      "  0.          0.        ]\n",
      "Step: 162, State history: [ 0.86191473 -0.57529274  0.96592218 -0.70372435 -0.31958819 -2.36217864\n",
      "  0.          0.        ]\n",
      "Step: 163, State history: [ 0.87783194 -0.54162383  1.0603341  -0.91762555 -0.62615232 -0.87420423\n",
      "  0.          0.        ]\n",
      "Step: 164, State history: [ 0.89465528 -0.54791225  1.13095986 -1.00413091 -0.74267788 -1.88042198\n",
      "  0.          0.        ]\n",
      "Step: 165, State history: [ 0.91306438 -0.56443889  1.19144925 -1.24561269 -1.06174396 -1.76859132\n",
      "  0.          0.        ]\n",
      "Step: 166, State history: [ 0.93983644 -0.56925865  1.29012825 -1.47640852 -1.37427338 -3.27407958\n",
      "  0.          0.        ]\n",
      "Step: 167, State history: [ 0.96593582 -0.58618428  1.42248325 -1.6603772  -1.79512543 -4.00898062\n",
      "  0.          0.        ]\n",
      "Step: 168, State history: [ 0.99516033 -0.58783615  1.59015775 -1.66719803 -2.1780902  -4.1987574\n",
      "  0.          0.        ]\n",
      "Step: 169, State history: [ 1.02908524 -0.58815925  1.8065344  -1.61290893 -2.44002176 -4.74410122\n",
      "  0.          0.        ]\n",
      "Step: 170, State history: [ 1.06065005 -0.5845061   2.01418223 -1.58691081 -2.77737448 -5.57120082\n",
      "  0.          0.        ]\n",
      "Step: 171, State history: [ 1.09562482 -0.63482712  2.22178262 -1.6208114  -3.20377927 -6.35052082\n",
      "  0.          0.        ]\n",
      "Step: 172, State history: [ 1.1303967  -0.64974433  2.44001381 -1.64325638 -3.69444237 -6.92865758\n",
      "  0.          0.        ]\n",
      "Step: 173, State history: [ 1.17374345 -0.66660306  2.6363872  -1.63815517 -4.10407408 -7.59856607\n",
      "  0.          0.        ]\n",
      "Step: 174, State history: [ 1.2155214  -0.68342988  2.78389119 -1.67340375 -4.50402616 -8.31014543\n",
      "  0.          0.        ]\n",
      "Step: 175, State history: [ 1.26391386 -0.69065384  2.96490602 -1.62758982 -4.9557721  -8.55598183\n",
      "  0.          0.        ]\n",
      "Step: 176, State history: [ 1.31328257 -0.71115164  3.12858637 -1.71023671 -5.32241514 -9.82786899\n",
      "  0.          0.        ]\n",
      "Step: 177, State history: [  1.36377558  -0.72353035   3.30594335  -1.65880062  -5.75979238\n",
      " -10.21918392   0.           0.        ]\n",
      "Step: 178, State history: [  1.42124459  -0.72623609   3.50316862  -1.70971558  -6.18739202\n",
      " -10.85133508   0.           0.        ]\n",
      "Step: 179, State history: [  1.47812882  -0.72458507   3.70304664  -1.72686268  -6.621876\n",
      " -11.40385733   0.           0.        ]\n",
      "Step: 180, State history: [  1.5423258   -0.72296326   3.91972462  -1.81516644  -7.07739881\n",
      " -12.28659357   0.           0.        ]\n",
      "Step: 181, State history: [  1.60608659  -0.74049622   4.11158984  -1.8161314   -7.51202688\n",
      " -12.96215898   0.           0.        ]\n",
      "Step: 182, State history: [  1.67518944  -0.74398231   4.32708767  -1.8679029   -7.99626878\n",
      " -13.79221276   0.           0.        ]\n",
      "Step: 183, State history: [  1.74781708  -0.76071506   4.53517625  -1.90832614  -8.44879235\n",
      " -14.46042325   0.           0.        ]\n",
      "Step: 184, State history: [  1.82363707  -0.75684135   4.76450727  -1.93231667  -8.95180877\n",
      " -15.38659374   0.           0.        ]\n",
      "Step: 185, State history: [  1.90511893  -0.77414714   4.9834723   -1.95819381  -9.44030021\n",
      " -15.94970846   0.           0.        ]\n",
      "Step: 186, State history: [  1.98635971  -0.77968426   5.20722835  -1.99532101  -9.94122312\n",
      " -16.69239852   0.           0.        ]\n",
      "Step: 187, State history: [  2.07617322  -0.77841051   5.46964483  -2.053467   -10.47185241\n",
      " -17.43129116   0.           0.        ]\n",
      "Step: 188, State history: [  2.16666705  -0.7980356    5.72097551  -2.19190452 -11.00942628\n",
      " -18.79527382   0.           0.        ]\n",
      "Step: 189, State history: [  2.26291121  -0.80887043   5.98970192  -2.25180762 -11.6087382\n",
      " -19.3365653    0.           0.        ]\n",
      "Step: 190, State history: [  2.36580419  -0.82014672   6.25838824  -2.32679472 -12.17142203\n",
      " -20.40590727   0.           0.        ]\n",
      "Step: 191, State history: [  2.47376454  -0.83440549   6.54312866  -2.37073101 -12.77550801\n",
      " -21.32099925   0.           0.        ]\n",
      "Step: 192, State history: [  2.58528885  -0.85926649   6.83969161  -2.50235658 -13.40540535\n",
      " -23.03750519   0.           0.        ]\n",
      "Step: 193, State history: [  2.7023052   -0.87606071   7.16272632  -2.52876767 -14.11522364\n",
      " -23.67501026   0.           0.        ]\n",
      "Step: 194, State history: [  2.82544376  -0.89690097   7.48710712  -2.60727348 -14.80056019\n",
      " -24.78321542   0.           0.        ]\n",
      "Step: 195, State history: [  2.95488509  -0.92031945   7.82427257  -2.69215288 -15.50980517\n",
      " -25.66500577   0.           0.        ]\n",
      "Step: 196, State history: [  3.09014173  -0.93178386   8.18848972  -2.7938603  -16.25365182\n",
      " -27.16538485   0.           0.        ]\n",
      "Step: 197, State history: [  3.22942061  -0.96026406   8.54653058  -2.88514468 -17.0318455\n",
      " -28.56320438   0.           0.        ]\n",
      "Step: 198, State history: [  3.37646038  -0.99353737   8.94643539  -2.95353273 -17.8511806\n",
      " -29.78197458   0.           0.        ]\n",
      "Step: 199, State history: [  3.53309635  -1.02416131   9.35505454  -3.08080646 -18.69369224\n",
      " -31.04656298   0.           0.        ]\n",
      "Step: 200, State history: [  3.69367845  -1.05298957   9.77204416  -3.17180207 -19.57591049\n",
      " -32.84256864   0.           0.        ]\n",
      "Step: 201, State history: [  3.86450082  -1.08963843  10.2167465   -3.2538264  -20.52005433\n",
      " -34.39447512   0.           0.        ]\n",
      "Step: 202, State history: [  4.04325656  -1.12160708  10.6939695   -3.35835051 -21.49315056\n",
      " -35.54248627   0.           0.        ]\n",
      "Step: 203, State history: [  4.23044644  -1.1654889   11.17885653  -3.50658706 -22.49004392\n",
      " -37.87367739   0.           0.        ]\n",
      "Step: 204, State history: [  4.42500671  -1.20459085  11.68074731  -3.5769253  -23.56940461\n",
      " -39.86135046   0.           0.        ]\n",
      "Step: 205, State history: [  4.63128955  -1.24139965  12.22528688  -3.66027905 -24.72116303\n",
      " -41.04704358   0.           0.        ]\n",
      "Step: 206, State history: [  4.84646868  -1.2868138   12.79510713  -3.82235367 -25.85602849\n",
      " -43.56619543   0.           0.        ]\n",
      "Step: 207, State history: [  5.07101043  -1.33297807  13.39392738  -3.92948138 -27.11264249\n",
      " -45.65620965   0.           0.        ]\n",
      "Step: 208, State history: [  5.30748557  -1.37424872  14.00953135  -4.04860978 -28.40330466\n",
      " -47.79951693   0.           0.        ]\n",
      "Step: 209, State history: [  5.55460314  -1.42520168  14.65570322  -4.16738376 -29.74331152\n",
      " -49.7988145    0.           0.        ]\n",
      "Step: 210, State history: [  5.81346913  -1.47310051  15.32599498  -4.32367649 -31.1381736\n",
      " -52.50620394   0.           0.        ]\n",
      "Step: 211, State history: [  6.08293589  -1.52260824  16.02142846  -4.44715117 -32.61632792\n",
      " -54.89315514   0.           0.        ]\n",
      "Step: 212, State history: [  6.3651576   -1.57398296  16.7501229   -4.60667205 -34.15126783\n",
      " -57.56034944   0.           0.        ]\n",
      "Step: 213, State history: [  6.66007702  -1.63333227  17.5049871   -4.76500089 -35.74603677\n",
      " -59.88771084   0.           0.        ]\n",
      "Step: 214, State history: [  6.96672097  -1.67527256  18.29388196  -4.92907287 -37.40521516\n",
      " -62.75635141   0.           0.        ]\n",
      "Step: 215, State history: [  7.28901556  -1.72675153  19.10886461  -5.06601648 -39.12117608\n",
      " -65.54802849   0.           0.        ]\n",
      "Step: 216, State history: [  7.62433951  -1.78540029  19.9788344   -5.24015529 -40.92340865\n",
      " -68.28610181   0.           0.        ]\n",
      "Step: 217, State history: [  7.97378598  -1.84393513  20.86558255  -5.47570445 -42.77183877\n",
      " -71.87060749   0.           0.        ]\n",
      "Step: 218, State history: [  8.33966855  -1.90279376  21.79656522  -5.64595901 -44.73766725\n",
      " -74.66929802   0.           0.        ]\n",
      "Step: 219, State history: [  8.72244494  -1.96789378  22.75812381  -5.86526775 -46.74900105\n",
      " -78.3323237    0.           0.        ]\n",
      "Step: 220, State history: [  9.12254953  -2.03214622  23.7693832   -6.0719509  -48.8689749\n",
      " -81.40937478   0.           0.        ]\n",
      "Step: 221, State history: [  9.53732103  -2.09855768  24.80266809  -6.27855836 -51.03772014\n",
      " -85.07479365   0.           0.        ]\n",
      "Step: 222, State history: [  9.97236755  -2.1733261   25.87928773  -6.50347536 -53.29881171\n",
      " -88.63617337   0.           0.        ]\n",
      "Step: 223, State history: [ 10.42381296  -2.24517484  27.00087238  -6.70543486 -55.63559909\n",
      " -92.50171579   0.           0.        ]\n",
      "-21718.296752327722\n"
     ]
    }
   ],
   "source": [
    "obs, _ = sim_env.reset()\n",
    "total_reward = 0\n",
    "for _ in range(200):\n",
    "    action = sim_env.action_space.sample()\n",
    "    obs, reward, done, done, info = sim_env.step(action)\n",
    "    total_reward += reward\n",
    "    sim_env.render(\"human\")\n",
    "    if done:\n",
    "        break\n",
    "sim_env.close()\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -3.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 383      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | -1.91e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 377           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031341295 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 3.68e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.73e+08      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00072      |\n",
      "|    value_loss           | 1.11e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-176.89 +/- 93.00\n",
      "Episode length: 90.00 +/- 18.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 90           |\n",
      "|    mean_reward          | -177         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.916809e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 1.67e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.32e+10     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -3.55e-05    |\n",
      "|    value_loss           | 1.27e+10     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -2.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 363       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 6000      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 53\u001b[0m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m             env\u001b[38;5;241m=\u001b[39mtrain_env,\n\u001b[1;32m     42\u001b[0m             n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m             clip_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     47\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 3 Layers with 64 neurons each policy network both\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Train the model and use the evaluation callback to save the best model.\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:207\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 59\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/Documents/pi-optimal/pi_optimal/utils/gym_wrapper/model_based_env.py:106\u001b[0m, in \u001b[0;36mModelBasedEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep_column\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep_column\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Create new dataset\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m inf_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTimeseriesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_processors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m state_input, action_input, _, _ \u001b[38;5;241m=\u001b[39m inf_dataset[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    109\u001b[0m state_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(state_input, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/pi-optimal/pi_optimal/datasets/timeseries_dataset.py:86\u001b[0m, in \u001b[0;36mTimeseriesDataset.__init__\u001b[0;34m(self, df, dataset_config, unit_index, timestep_column, reward_column, state_columns, action_columns, lookback_timesteps, forecast_timesteps, train_processors, is_inference, noise_intensity_on_past_states, verbose, use_padding)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_column\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m episodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m state features and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m actions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_episode_boundaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_timestep_boundaries()\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_processors \u001b[38;5;241m=\u001b[39m train_processors\n",
      "File \u001b[0;32m~/Documents/pi-optimal/pi_optimal/datasets/timeseries_dataset.py:514\u001b[0m, in \u001b[0;36mTimeseriesDataset._calculate_episode_boundaries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_calculate_episode_boundaries\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    511\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m    Calculate the start and end indices for each episode in the dataset.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     episode_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode_column\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_end_index \u001b[38;5;241m=\u001b[39m episode_sizes\u001b[38;5;241m.\u001b[39mcumsum()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_start_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_end_index[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:3043\u001b[0m, in \u001b[0;36mGroupBy.size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2986\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2987\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(see_also\u001b[38;5;241m=\u001b[39m_common_see_also)\n\u001b[1;32m   2988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   2989\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2990\u001b[0m \u001b[38;5;124;03m    Compute group sizes.\u001b[39;00m\n\u001b[1;32m   2991\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3041\u001b[0m \u001b[38;5;124;03m    Freq: MS, dtype: int64\u001b[39;00m\n\u001b[1;32m   3042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3043\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3044\u001b[0m     dtype_backend: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy_nullable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:705\u001b[0m, in \u001b[0;36mBaseGrouper.size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m    702\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    Compute group sizes.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     ids, _, ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m\n\u001b[1;32m    706\u001b[0m     out: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ngroups:\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:745\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 745\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    748\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:769\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[1;32m    768\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_group_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:691\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:835\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/algorithms.py:802\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[1;32m    796\u001b[0m         values,\n\u001b[1;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[1;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[1;32m    799\u001b[0m     )\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/algorithms.py:1563\u001b[0m, in \u001b[0;36msafe_sort\u001b[0;34m(values, codes, use_na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1563\u001b[0m     new_codes \u001b[38;5;241m=\u001b[39m \u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     reverse_indexer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(sorter), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import gymnasium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "# Monkey-patch gym to include a __version__ attribute if it's missing.\n",
    "\n",
    "# Set up log folder for monitoring\n",
    "log_dir = \"./logs_dir/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create the training environment and wrap it with a Monitor to log rewards.\n",
    "train_env = sim_env\n",
    "train_env = Monitor(train_env, log_dir)\n",
    "\n",
    "# Create a separate evaluation environment.\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "eval_env = Monitor(eval_env, log_dir)\n",
    "\n",
    "# Set up the evaluation callback. This will evaluate the model every 5000 timesteps,\n",
    "# and save the model if it achieves a new best mean reward.\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=os.path.join(log_dir, 'best_model'),\n",
    "    log_path=log_dir,\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=50,\n",
    "    deterministic=False,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\"MlpPolicy\",\n",
    "            env=train_env,\n",
    "            n_steps=2000,\n",
    "            batch_size=64,\n",
    "            gamma=0.99,\n",
    "            n_epochs=10,\n",
    "            clip_range=0.2,\n",
    "            verbose=1)\n",
    "\n",
    "# 3 Layers with 64 neurons each policy network both\n",
    "# \n",
    "\n",
    "# Train the model and use the evaluation callback to save the best model.\n",
    "model.learn(total_timesteps=300000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = PPO.load(os.path.join(log_dir, 'best_model/best_model.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 17:08:34.886 Python[1576:23869] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-09 17:08:34.887 Python[1576:23869] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 49.49009550974978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"human\")   \n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "terminated = False\n",
    "total_reward = 0\n",
    "while not (done or terminated):\n",
    "    # Predict the next action using the trained policy.\n",
    "    action, _ = best_model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, terminated ,_ = env.step(action)\n",
    "    total_reward += reward\n",
    "    env.render()\n",
    "\n",
    "env.close()\n",
    "print(f\"Total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -5.288970231821338\n",
      "Total reward: 26.286912093857694\n",
      "Total reward: -12.856226673468612\n",
      "Total reward: 12.946497926210256\n",
      "Total reward: 38.60115129334602\n",
      "Total reward: 18.78524829945077\n",
      "Total reward: 35.285303981524294\n",
      "Total reward: 14.526711042461073\n",
      "Total reward: 17.797928607848448\n",
      "Total reward: 42.06150815568901\n",
      "Total reward: 28.097011554536124\n",
      "Total reward: 36.0323057969143\n",
      "Total reward: 62.95725373502157\n",
      "Total reward: 22.9625340032443\n",
      "Total reward: 9.385850641281905\n",
      "Total reward: 85.13013116307755\n",
      "Total reward: 56.36120356538578\n",
      "Total reward: 27.501199298959094\n",
      "Total reward: 35.1031880145066\n",
      "Total reward: -8.861749677979049\n",
      "Total reward: 10.024359557117094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     obs, reward, done, terminated ,_ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     13\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m---> 14\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m all_rewards\u001b[38;5;241m.\u001b[39mappend(total_reward)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/wrappers/common.py:409\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m     )\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/wrappers/common.py:303\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/envs/box2d/lunar_lander.py:739\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mcircle(\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    733\u001b[0m         color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor2,\n\u001b[1;32m    734\u001b[0m         center\u001b[38;5;241m=\u001b[39mtrans \u001b[38;5;241m*\u001b[39m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    735\u001b[0m         radius\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    736\u001b[0m     )\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     path \u001b[38;5;241m=\u001b[39m [trans \u001b[38;5;241m*\u001b[39m v \u001b[38;5;241m*\u001b[39m SCALE \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mvertices]\n\u001b[1;32m    740\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mpolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor1, points\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m    741\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, path, obj\u001b[38;5;241m.\u001b[39mcolor1)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/envs/box2d/lunar_lander.py:739\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    731\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mcircle(\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    733\u001b[0m         color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor2,\n\u001b[1;32m    734\u001b[0m         center\u001b[38;5;241m=\u001b[39mtrans \u001b[38;5;241m*\u001b[39m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    735\u001b[0m         radius\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    736\u001b[0m     )\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     path \u001b[38;5;241m=\u001b[39m [trans \u001b[38;5;241m*\u001b[39m v \u001b[38;5;241m*\u001b[39m SCALE \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mvertices]\n\u001b[1;32m    740\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mpolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor1, points\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m    741\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, path, obj\u001b[38;5;241m.\u001b[39mcolor1)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"rgb_array\")  \n",
    "all_rewards = []\n",
    "for i in range(100):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    terminated = False\n",
    "    total_reward = 0\n",
    "    while not (done or terminated):\n",
    "        # Predict the next action using the trained policy.\n",
    "        action, _ = best_model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, terminated ,_ = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "    all_rewards.append(total_reward)\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.31434120791784"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 1 model\n",
    "np.mean(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">No eval environment provided, will not create eval callback</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Creating PPO model</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Training model</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 147       |\n",
      "|    ep_rew_mean     | -2.01e+06 |\n",
      "| time/              |           |\n",
      "|    fps             | 177       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 11        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 161           |\n",
      "|    ep_rew_mean          | -1.2e+06      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 167           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2118835e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.3e+11       |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | 6.9e-06       |\n",
      "|    value_loss           | 1.17e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 165           |\n",
      "|    ep_rew_mean          | -1.07e+07     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 168           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4334801e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -5.11e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.73e+09      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    value_loss           | 6.09e+09      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pi_optimal.planners.online_planner import OnlinePlanner\n",
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=[nn_model, nn_model2, nn_model3], dataset=dataset_train, max_episode_steps=200)\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "\n",
    "online_planner = OnlinePlanner(env=sim_env, eval_env=None, train_params={\"total_timesteps\": 6000}, eval_params={\"n_eval_episodes\": 50, \"eval_freq\": 5000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Inference from a dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details  look in to the predict function of the planer. It takes the last observation and uses it as observation. Ensure that the dataset is set to **is_inference == True** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|██████████| 50/50 [00:00<00:00, 5438.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">⚙️</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Dataset has 50 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Dataset has 1 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">📝</span>\n",
       "                <span class=\"logger-message\">Using processors provided in the dataset_configuration.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">⚙️</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean 0.11 and std 0.33'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✅</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">✨</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_inf = data_collector.collect(n_steps=50, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "\n",
    "dataset_inf = dataset_test = TimeseriesDataset(\n",
    "    df=df_inf,\n",
    "    dataset_config=dataset_config,\n",
    "    train_processors=False,\n",
    "    is_inference=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_planner.plan(dataset_inf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi-optimal-RKvx2dB5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
