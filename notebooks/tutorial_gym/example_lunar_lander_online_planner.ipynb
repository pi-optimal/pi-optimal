{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "Import required libraries including NumPy, sklearn with Intel extension, and pi_optimal utilities. Configure warning suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment and Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "#from sklearnex import patch_sklearn\n",
    "import warnings\n",
    "\n",
    "# Change directory to the parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Apply Intel extension to sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import pi_optimal utilities\n",
    "from pi_optimal.utils.data_generators.gym_data_generator import GymDataGenerator\n",
    "from pi_optimal.datasets.timeseries_dataset import TimeseriesDataset\n",
    "from pi_optimal.models.sklearn.random_forest_model import RandomForest\n",
    "from pi_optimal.models.sklearn.mlp import NeuralNetwork\n",
    "from pi_optimal.evaluators.base_evaluator import BaseEvaluator\n",
    "from pi_optimal.evaluators.plotting import plot_n_step_evaluation, plot_n_step_episode_rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gym Data Generator\n",
    "Initialize GymDataGenerator with LunarLander environment and collect training and test data with specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 41759.05it/s]\n",
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00<00:00, 47382.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create Gym Data Generator\n",
    "\n",
    "# Initialize GymDataGenerator with LunarLander environment\n",
    "data_collector = GymDataGenerator(env_name=\"LunarLander-v3\")\n",
    "\n",
    "# Collect training data\n",
    "df_train = data_collector.collect(n_steps=10000, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "df_test = data_collector.collect(n_steps=5000, max_steps_per_episode=200, env_seed=None, action_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tutorial_gym/dataset_20250401_160426.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtutorial_gym/dataset_20250401_160426.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tutorial_gym/dataset_20250401_160426.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"tutorial_gym/dataset_20250401_160426.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'episode_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'episode_id'"
     ]
    }
   ],
   "source": [
    "df_train[\"reward\"] = df_train.groupby(\"episode_id\").reward.shift(1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Dataset Parameters\n",
    "Set up dataset configuration dictionary defining features, processors, and evaluation metrics for states, actions, and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Dataset Parameters\n",
    "\n",
    "# Define dataset configuration dictionary\n",
    "dataset_config = {\n",
    "    \"episode_column\": \"episode\",\n",
    "    \"timestep_column\": \"step\",\n",
    "    \"states\": {\n",
    "        0: {\"name\": \"state_0\", \"type\": \"numerical\", \"processor\": {\"name\": \"StandardScaler\"}, \"evaluation_metric\": \"mae\"},\n",
    "        1: {\"name\": \"state_1\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        2: {\"name\": \"state_2\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        3: {\"name\": \"state_3\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        4: {\"name\": \"state_4\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        5: {\"name\": \"state_5\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "        6: {\"name\": \"state_6\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        7: {\"name\": \"state_7\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        8: {\"name\": \"done\", \"type\": \"binary\", \"processor\": None, \"evaluation_metric\": \"f1_binary\"},\n",
    "        9: {\"name\": \"reward\", \"type\": \"numerical\", \"processor\": {\"name\": \"RobustScaler\", \"params\": {\"quantile_range\": (5.0, 95.0)}}, \"evaluation_metric\": \"mae\"},\n",
    "    },\n",
    "    \"actions\": {\n",
    "        0: {\"name\": \"action_0\", \"type\": \"categorial\", \"processor\": {\"name\": \"OneHotEncoder\"}},\n",
    "    },\n",
    "    \"reward_feature_idx\": 9,\n",
    "    \"reward_vector_idx\": 9,\n",
    "    \"reward_column\": \"reward\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Test Datasets\n",
    "Initialize TimeseriesDataset objects with collected data, applying the configuration and setting lookback/forecast windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10000 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 113 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Fitting feature processors...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Processors created and fitted</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean -0.01 and std 0.29'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Training and Test Datasets\n",
    "\n",
    "# Define lookback and forecast timesteps\n",
    "LOOKBACK_TIMESTEPS = 10\n",
    "FORECAST_TIMESTEPS = 1\n",
    "\n",
    "# Initialize TimeseriesDataset objects for training and test data\n",
    "dataset_train = TimeseriesDataset(\n",
    "    df=df_train,\n",
    "    dataset_config=dataset_config,\n",
    "    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "    forecast_timesteps=FORECAST_TIMESTEPS,\n",
    "    train_processors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network Model\n",
    "Create and train a Neural Network model with specified hyperparameters on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575995f56ed6439798e53d0590a340aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pi_optimal.models.torch.mlp import NeuralNetworkTorch\n",
    "models = []\n",
    "for i in range(1):\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model1 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001,}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model1.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f6c3fced9b483c9779ed8cae42b221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model2 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001,}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model2.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373506bf27e54a32b2eecd6bcebb2531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model3 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model3.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea9ee2e1076485e8cdd06d0459ed2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model4 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model4.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4ef67634b0454a84fbc81236adc0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model5 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model5.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74848854c50447c83fa0ed81086ebdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model6 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model6.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02709b35df54488c8647ecc63e72111a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model7 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model7.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0092651c9dd415aa191ca7cb0bb4bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model8 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model8.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3fa421442f4711ba1fdd7ba239fedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model9 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model9.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f61d1a5981f43f6941dccb99b03e187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize Neural Network model with specified hyperparameters\n",
    "nn_model10 = NeuralNetwork(params={\n",
    "    \"hidden_layer_sizes\": (128, 128),\n",
    "    \"alpha\": 0.01,\n",
    "    \"learning_rate_init\": 0.001}\n",
    ")\n",
    "    \n",
    "# Train the Neural Network model on the first training dataset\n",
    "nn_model10.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Workflow\n",
    "\n",
    "Here you could see how it works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=models, dataset=dataset_train, max_episode_steps=200, use_start_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12, State history: [-0.00470073  1.34486113 -0.07679896 -0.38653565  0.05215874  0.08994773\n",
      "  0.          0.        ]\n",
      "Step: 13, State history: [-0.01410913  1.32018666 -0.04364895 -0.41056232  0.05746433  0.1645839\n",
      "  0.          0.        ]\n",
      "Step: 14, State history: [-0.00573451  1.34256692 -0.03274342 -0.41341624  0.05369352  0.1382038\n",
      "  0.          0.        ]\n",
      "Step: 15, State history: [-0.00135175  1.31640741 -0.05056884 -0.43816871  0.06746983  0.12415782\n",
      "  0.          0.        ]\n",
      "Step: 16, State history: [-0.00618959  1.30754704 -0.0563117  -0.44799178  0.05307124  0.10002305\n",
      "  0.          0.        ]\n",
      "Step: 17, State history: [-0.01331905  1.29178258 -0.07776237 -0.42933553  0.06300507  0.12323796\n",
      "  0.          0.        ]\n",
      "Step: 18, State history: [-0.00783595  1.28365262 -0.04696333 -0.46053702  0.07305327  0.14354231\n",
      "  0.          0.        ]\n",
      "Step: 19, State history: [-0.0084333   1.27871331 -0.05872541 -0.47863985  0.09516768  0.13996049\n",
      "  0.          0.        ]\n",
      "Step: 20, State history: [-0.01041328  1.2496906  -0.08754052 -0.42670747  0.09396291  0.11932978\n",
      "  0.          0.        ]\n",
      "Step: 21, State history: [-0.01483484  1.24587219 -0.07110311 -0.40499646  0.07282512  0.08509522\n",
      "  0.          0.        ]\n",
      "Step: 22, State history: [-0.01305763  1.22146158 -0.12070692 -0.44261747  0.09481469  0.08802297\n",
      "  0.          0.        ]\n",
      "Step: 23, State history: [-0.0094498   1.23108682 -0.08340619 -0.45642755  0.09021196  0.18258195\n",
      "  0.          0.        ]\n",
      "Step: 24, State history: [-0.01588906  1.18362514 -0.10548425 -0.47511801  0.12025205  0.21948128\n",
      "  0.          0.        ]\n",
      "Step: 25, State history: [-0.0085192   1.22093853 -0.10216547 -0.50946448  0.10358807  0.22550664\n",
      "  0.          0.        ]\n",
      "Step: 26, State history: [-0.02229622  1.19270152 -0.09398808 -0.51605838  0.10177884  0.23293869\n",
      "  0.          0.        ]\n",
      "Step: 27, State history: [-0.01739046  1.18145968 -0.08451114 -0.50511348  0.15307696  0.20286865\n",
      "  0.          0.        ]\n",
      "Step: 28, State history: [-0.01572059  1.1819521  -0.06506232 -0.54006565  0.15675395  0.17898589\n",
      "  0.          0.        ]\n",
      "Step: 29, State history: [-0.02076919  1.16120234 -0.0908942  -0.57541521  0.1605422   0.17063112\n",
      "  0.          0.        ]\n",
      "Step: 30, State history: [-0.01906765  1.13316768 -0.0613734  -0.61385772  0.16867533  0.14684616\n",
      "  0.          0.        ]\n",
      "Step: 31, State history: [-0.01767869  1.17539816 -0.07178796 -0.62559517  0.16537732  0.09291853\n",
      "  0.          0.        ]\n",
      "Step: 32, State history: [-0.01088993  1.13111765 -0.02837601 -0.66222601  0.19879842  0.08465654\n",
      "  0.          0.        ]\n",
      "Step: 33, State history: [-0.0187277   1.10403423 -0.05764477 -0.70436729  0.16684286  0.11219311\n",
      "  0.          0.        ]\n",
      "Step: 34, State history: [-0.01990142  1.05227392 -0.03707431 -0.70839172  0.16101074  0.06538016\n",
      "  0.          0.        ]\n",
      "Step: 35, State history: [-0.01919644  1.09171308 -0.01234983 -0.7237579   0.17823322  0.08418576\n",
      "  0.          0.        ]\n",
      "Step: 36, State history: [-0.02323692  1.06500771 -0.05068055 -0.75825222  0.18986065  0.10922089\n",
      "  0.          0.        ]\n",
      "Step: 37, State history: [-0.0206022   1.04463082 -0.01668573 -0.7911512   0.17756658  0.13794282\n",
      "  0.          0.        ]\n",
      "Step: 38, State history: [-0.01642693  1.01155791 -0.04848645 -0.83433275  0.19958257  0.10518585\n",
      "  0.          0.        ]\n",
      "Step: 39, State history: [-0.01637506  1.01550531 -0.03764599 -0.8359138   0.1826331   0.13841568\n",
      "  0.          0.        ]\n",
      "Step: 40, State history: [-0.030526    0.98229059 -0.04314493 -0.88722055  0.20328128  0.10351402\n",
      "  0.          0.        ]\n",
      "Step: 41, State history: [-0.01883387  0.96073819 -0.07752732 -0.90377504  0.21636538  0.17368589\n",
      "  0.          0.        ]\n",
      "Step: 42, State history: [-0.02225192  0.92466403 -0.09512316 -0.86670117  0.21114167  0.1486879\n",
      "  0.          0.        ]\n",
      "Step: 43, State history: [-0.02103093  0.96495571 -0.08480259 -0.83880332  0.23071926  0.15453001\n",
      "  0.          0.        ]\n",
      "Step: 44, State history: [-0.03163671  0.95711982 -0.09670074 -0.81280617  0.19473482  0.15763324\n",
      "  0.          0.        ]\n",
      "Step: 45, State history: [-0.02724636  0.87113852 -0.08293478 -0.8916317   0.24824962  0.15034642\n",
      "  0.          0.        ]\n",
      "Step: 46, State history: [-0.02304714  0.85584117 -0.08442731 -0.90660495  0.24261293  0.18706567\n",
      "  0.          0.        ]\n",
      "Step: 47, State history: [-0.02627249  0.86271225 -0.08626157 -0.91419017  0.24713709  0.09709048\n",
      "  0.          0.        ]\n",
      "Step: 48, State history: [-0.0236109   0.80147813 -0.07876563 -0.97481522  0.28591703  0.16160144\n",
      "  0.          0.        ]\n",
      "Step: 49, State history: [-0.026663    0.78721758 -0.07408268 -0.95288108  0.26436579  0.14282782\n",
      "  0.          0.        ]\n",
      "Step: 50, State history: [-0.0282753   0.75342739 -0.10864341 -0.98770045  0.26635804  0.18962867\n",
      "  0.          0.        ]\n",
      "Step: 51, State history: [-0.02370298  0.75170564 -0.08929506 -1.04601598  0.26493331  0.19218653\n",
      "  0.          0.        ]\n",
      "Step: 52, State history: [-0.03448238  0.72098813 -0.11805333 -1.10005973  0.33823388  0.19965833\n",
      "  0.          0.        ]\n",
      "Step: 53, State history: [-0.0339458   0.71655649 -0.12272211 -1.10848514  0.28205177  0.20861928\n",
      "  0.          0.        ]\n",
      "Step: 54, State history: [-0.03657346  0.68195321 -0.12081803 -1.08074425  0.31140107  0.18877782\n",
      "  0.          0.        ]\n",
      "Step: 55, State history: [-0.03704492  0.62620484 -0.10657349 -1.12639667  0.30288042  0.16803185\n",
      "  0.          0.        ]\n",
      "Step: 56, State history: [-0.04089883  0.61314689 -0.13621678 -1.16434152  0.32535888  0.11979255\n",
      "  0.          0.        ]\n",
      "Step: 57, State history: [-0.02829062  0.60754383 -0.13225967 -1.16057096  0.32516183  0.04989408\n",
      "  0.          0.        ]\n",
      "Step: 58, State history: [-0.04433838  0.55800003 -0.11298619 -1.19098329  0.30461278  0.06458737\n",
      "  0.          0.        ]\n",
      "Step: 59, State history: [-0.04213485  0.54648489 -0.10519806 -1.20872888  0.32813212  0.06620161\n",
      "  0.          0.        ]\n",
      "Step: 60, State history: [-3.83292581e-02  5.16566755e-01 -1.02727159e-01 -1.25048349e+00\n",
      "  3.16314008e-01 -1.04258349e-04  0.00000000e+00  0.00000000e+00]\n",
      "Step: 61, State history: [-0.05071217  0.4945377  -0.13334773 -1.22626899  0.33178513  0.02568667\n",
      "  0.          0.        ]\n",
      "Step: 62, State history: [-0.04018201  0.42600589 -0.12075096 -1.25697551  0.32738394  0.06962729\n",
      "  0.          0.        ]\n",
      "Step: 63, State history: [-0.05300053  0.43316813 -0.17698334 -1.21936979  0.35496166  0.04496417\n",
      "  0.          0.        ]\n",
      "Step: 64, State history: [-0.05255711  0.37530956 -0.13903151 -1.2622237   0.31679697  0.08631483\n",
      "  0.          0.        ]\n",
      "Step: 65, State history: [-0.05409201  0.36460143 -0.17134753 -1.29125474  0.3464175   0.17818864\n",
      "  0.          0.        ]\n",
      "Step: 66, State history: [-0.05470905  0.34065543 -0.19701284 -1.3446225   0.32997339  0.07380276\n",
      "  0.          0.        ]\n",
      "Step: 67, State history: [-0.04134306  0.31646477 -0.22248013 -1.27300407  0.32361132  0.0799308\n",
      "  0.          0.        ]\n",
      "Step: 68, State history: [-0.05414282  0.27825306 -0.18286692 -1.29283723  0.35010497  0.0930183\n",
      "  0.          0.        ]\n",
      "Step: 69, State history: [-0.06158785  0.23604681 -0.21235224 -1.36585779  0.34686353  0.09469159\n",
      "  0.          0.        ]\n",
      "Step: 70, State history: [-0.06881558  0.19204081 -0.25059946 -1.29779754  0.31625452  0.12943043\n",
      "  0.          0.        ]\n",
      "Step: 71, State history: [-0.0696912   0.164074   -0.23305109 -1.30677977  0.34881289  0.14816622\n",
      "  0.          0.        ]\n",
      "Step: 72, State history: [-0.06502926  0.1613981  -0.26431933 -1.37776535  0.3954552   0.14375932\n",
      "  0.          0.        ]\n",
      "Step: 73, State history: [-0.07139529  0.1445386  -0.23404856 -1.34448632  0.39743947  0.16877995\n",
      "  0.          0.        ]\n",
      "Step: 74, State history: [-0.06328288  0.10231563 -0.25707407 -1.38907909  0.37651835  0.1430093\n",
      "  0.          0.        ]\n",
      "Step: 75, State history: [-0.07597253  0.09889693 -0.25341988 -1.37155236  0.36986083  0.0874624\n",
      "  0.          0.        ]\n",
      "Step: 76, State history: [-0.07749525  0.04102205 -0.32796891 -1.34486969  0.36800334  0.14765374\n",
      "  0.          0.        ]\n",
      "Step: 77, State history: [-0.08950451  0.04345331 -0.30454783 -1.4046825   0.38407219  0.10504332\n",
      "  0.          1.        ]\n",
      "Step: 78, State history: [-0.08261926 -0.02412205 -0.13763988 -1.24577473  0.47865657 -0.17695606\n",
      "  0.          1.        ]\n",
      "Step: 79, State history: [-0.08193875 -0.02994139 -0.0946337  -0.81767143  0.30182916 -3.0397124\n",
      "  0.          1.        ]\n",
      "-105.3994454073834\n"
     ]
    }
   ],
   "source": [
    "obs, _ = sim_env.reset()\n",
    "total_reward = 0\n",
    "for _ in range(200):\n",
    "    action = sim_env.action_space.sample()\n",
    "    obs, reward, done, done, info = sim_env.step(action)\n",
    "    total_reward += reward\n",
    "    sim_env.render(\"human\")\n",
    "    if done:\n",
    "        break\n",
    "sim_env.close()\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -3.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 383      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | -1.91e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 377           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031341295 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 3.68e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.73e+08      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00072      |\n",
      "|    value_loss           | 1.11e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-176.89 +/- 93.00\n",
      "Episode length: 90.00 +/- 18.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 90           |\n",
      "|    mean_reward          | -177         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.916809e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 1.67e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.32e+10     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -3.55e-05    |\n",
      "|    value_loss           | 1.27e+10     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -2.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 363       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 6000      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 53\u001b[0m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m             env\u001b[38;5;241m=\u001b[39mtrain_env,\n\u001b[1;32m     42\u001b[0m             n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m             clip_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     47\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 3 Layers with 64 neurons each policy network both\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Train the model and use the evaluation callback to save the best model.\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:207\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 59\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/Documents/pi-optimal/pi_optimal/utils/gym_wrapper/model_based_env.py:106\u001b[0m, in \u001b[0;36mModelBasedEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep_column\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestep_column\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Create new dataset\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m inf_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTimeseriesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_processors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m state_input, action_input, _, _ \u001b[38;5;241m=\u001b[39m inf_dataset[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    109\u001b[0m state_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(state_input, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/pi-optimal/pi_optimal/datasets/timeseries_dataset.py:86\u001b[0m, in \u001b[0;36mTimeseriesDataset.__init__\u001b[0;34m(self, df, dataset_config, unit_index, timestep_column, reward_column, state_columns, action_columns, lookback_timesteps, forecast_timesteps, train_processors, is_inference, noise_intensity_on_past_states, verbose, use_padding)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_column\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m episodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m state features and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m actions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_episode_boundaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_timestep_boundaries()\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_processors \u001b[38;5;241m=\u001b[39m train_processors\n",
      "File \u001b[0;32m~/Documents/pi-optimal/pi_optimal/datasets/timeseries_dataset.py:514\u001b[0m, in \u001b[0;36mTimeseriesDataset._calculate_episode_boundaries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_calculate_episode_boundaries\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    511\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m    Calculate the start and end indices for each episode in the dataset.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     episode_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode_column\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_end_index \u001b[38;5;241m=\u001b[39m episode_sizes\u001b[38;5;241m.\u001b[39mcumsum()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_start_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_end_index[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:3043\u001b[0m, in \u001b[0;36mGroupBy.size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2986\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2987\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(see_also\u001b[38;5;241m=\u001b[39m_common_see_also)\n\u001b[1;32m   2988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   2989\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2990\u001b[0m \u001b[38;5;124;03m    Compute group sizes.\u001b[39;00m\n\u001b[1;32m   2991\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3041\u001b[0m \u001b[38;5;124;03m    Freq: MS, dtype: int64\u001b[39;00m\n\u001b[1;32m   3042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3043\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3044\u001b[0m     dtype_backend: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy_nullable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:705\u001b[0m, in \u001b[0;36mBaseGrouper.size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m    702\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    Compute group sizes.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     ids, _, ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m\n\u001b[1;32m    706\u001b[0m     out: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ngroups:\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:745\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 745\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    748\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/ops.py:769\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[1;32m    768\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_group_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:691\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:835\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/algorithms.py:802\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[1;32m    796\u001b[0m         values,\n\u001b[1;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[1;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[1;32m    799\u001b[0m     )\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/algorithms.py:1563\u001b[0m, in \u001b[0;36msafe_sort\u001b[0;34m(values, codes, use_na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1563\u001b[0m     new_codes \u001b[38;5;241m=\u001b[39m \u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     reverse_indexer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(sorter), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import gymnasium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "# Monkey-patch gym to include a __version__ attribute if it's missing.\n",
    "\n",
    "# Set up log folder for monitoring\n",
    "log_dir = \"./logs_dir/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create the training environment and wrap it with a Monitor to log rewards.\n",
    "train_env = sim_env\n",
    "train_env = Monitor(train_env, log_dir)\n",
    "\n",
    "# Create a separate evaluation environment.\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "eval_env = Monitor(eval_env, log_dir)\n",
    "\n",
    "# Set up the evaluation callback. This will evaluate the model every 5000 timesteps,\n",
    "# and save the model if it achieves a new best mean reward.\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=os.path.join(log_dir, 'best_model'),\n",
    "    log_path=log_dir,\n",
    "    eval_freq=5000,\n",
    "    n_eval_episodes=50,\n",
    "    deterministic=False,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "model = PPO(\"MlpPolicy\",\n",
    "            env=train_env,\n",
    "            n_steps=2000,\n",
    "            batch_size=64,\n",
    "            gamma=0.99,\n",
    "            n_epochs=10,\n",
    "            clip_range=0.2,\n",
    "            verbose=1)\n",
    "\n",
    "# 3 Layers with 64 neurons each policy network both\n",
    "# \n",
    "\n",
    "# Train the model and use the evaluation callback to save the best model.\n",
    "model.learn(total_timesteps=300000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = PPO.load(os.path.join(log_dir, 'best_model/best_model.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 17:08:34.886 Python[1576:23869] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-09 17:08:34.887 Python[1576:23869] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 49.49009550974978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"human\")   \n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "terminated = False\n",
    "total_reward = 0\n",
    "while not (done or terminated):\n",
    "    # Predict the next action using the trained policy.\n",
    "    action, _ = best_model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, terminated ,_ = env.step(action)\n",
    "    total_reward += reward\n",
    "    env.render()\n",
    "\n",
    "env.close()\n",
    "print(f\"Total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -5.288970231821338\n",
      "Total reward: 26.286912093857694\n",
      "Total reward: -12.856226673468612\n",
      "Total reward: 12.946497926210256\n",
      "Total reward: 38.60115129334602\n",
      "Total reward: 18.78524829945077\n",
      "Total reward: 35.285303981524294\n",
      "Total reward: 14.526711042461073\n",
      "Total reward: 17.797928607848448\n",
      "Total reward: 42.06150815568901\n",
      "Total reward: 28.097011554536124\n",
      "Total reward: 36.0323057969143\n",
      "Total reward: 62.95725373502157\n",
      "Total reward: 22.9625340032443\n",
      "Total reward: 9.385850641281905\n",
      "Total reward: 85.13013116307755\n",
      "Total reward: 56.36120356538578\n",
      "Total reward: 27.501199298959094\n",
      "Total reward: 35.1031880145066\n",
      "Total reward: -8.861749677979049\n",
      "Total reward: 10.024359557117094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     obs, reward, done, terminated ,_ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     13\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m---> 14\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m all_rewards\u001b[38;5;241m.\u001b[39mappend(total_reward)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/wrappers/common.py:409\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m     )\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/wrappers/common.py:303\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/envs/box2d/lunar_lander.py:739\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mcircle(\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    733\u001b[0m         color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor2,\n\u001b[1;32m    734\u001b[0m         center\u001b[38;5;241m=\u001b[39mtrans \u001b[38;5;241m*\u001b[39m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    735\u001b[0m         radius\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    736\u001b[0m     )\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     path \u001b[38;5;241m=\u001b[39m [trans \u001b[38;5;241m*\u001b[39m v \u001b[38;5;241m*\u001b[39m SCALE \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mvertices]\n\u001b[1;32m    740\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mpolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor1, points\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m    741\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, path, obj\u001b[38;5;241m.\u001b[39mcolor1)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/pi-optimal-RKvx2dB5-py3.10/lib/python3.10/site-packages/gymnasium/envs/box2d/lunar_lander.py:739\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    731\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mcircle(\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    733\u001b[0m         color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor2,\n\u001b[1;32m    734\u001b[0m         center\u001b[38;5;241m=\u001b[39mtrans \u001b[38;5;241m*\u001b[39m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    735\u001b[0m         radius\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mradius \u001b[38;5;241m*\u001b[39m SCALE,\n\u001b[1;32m    736\u001b[0m     )\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     path \u001b[38;5;241m=\u001b[39m [trans \u001b[38;5;241m*\u001b[39m v \u001b[38;5;241m*\u001b[39m SCALE \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mvertices]\n\u001b[1;32m    740\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mpolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor1, points\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m    741\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, path, obj\u001b[38;5;241m.\u001b[39mcolor1)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained agent by running one episode and rendering it.\n",
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"rgb_array\")  \n",
    "all_rewards = []\n",
    "for i in range(100):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    terminated = False\n",
    "    total_reward = 0\n",
    "    while not (done or terminated):\n",
    "        # Predict the next action using the trained policy.\n",
    "        action, _ = best_model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, terminated ,_ = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "    all_rewards.append(total_reward)\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.31434120791784"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 1 model\n",
    "np.mean(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">No eval environment provided, will not create eval callback</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Creating PPO model</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Training model</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 147       |\n",
      "|    ep_rew_mean     | -2.01e+06 |\n",
      "| time/              |           |\n",
      "|    fps             | 177       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 11        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 161           |\n",
      "|    ep_rew_mean          | -1.2e+06      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 167           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2118835e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.3e+11       |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | 6.9e-06       |\n",
      "|    value_loss           | 1.17e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 165           |\n",
      "|    ep_rew_mean          | -1.07e+07     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 168           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4334801e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | -5.11e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.73e+09      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    value_loss           | 6.09e+09      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pi_optimal.planners.online_planner import OnlinePlanner\n",
    "from pi_optimal.utils.gym_wrapper.model_based_env import ModelBasedEnv\n",
    "\n",
    "sim_env = ModelBasedEnv(models=[nn_model, nn_model2, nn_model3], dataset=dataset_train, max_episode_steps=200)\n",
    "eval_env = gymnasium.make(\"LunarLander-v3\")\n",
    "\n",
    "online_planner = OnlinePlanner(env=sim_env, eval_env=None, train_params={\"total_timesteps\": 6000}, eval_params={\"n_eval_episodes\": 50, \"eval_freq\": 5000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Inference from a dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details  look in to the predict function of the planer. It takes the last observation and uses it as observation. Ensure that the dataset is set to **is_inference == True** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 5438.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id='logger-container'>\n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Initializing new dataset...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 50 rows and 13 columns.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 1 episodes.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Dataset has 10 state features and 1 actions.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">üìù</span>\n",
       "                <span class=\"logger-message\">Using processors provided in the dataset_configuration.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"1\" style=\"margin-left: 20px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚öôÔ∏è</span>\n",
       "                <span class=\"logger-message\">Transforming features...</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_0' using preprocessor 'StandardScaler() with mean 0.11 and std 0.33'.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_1' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_2' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_3' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_4' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_5' using preprocessor 'RobustScaler(quantile_range=(5.0, 95.0)) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_6' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'state_7' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'done' using preprocessor 'None '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed states feature 'reward' using preprocessor 'PowerTransformer() '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"2\" style=\"margin-left: 40px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚úÖ</span>\n",
       "                <span class=\"logger-message\">Transformed actions feature 'action_0' using preprocessor 'OneHotEncoder(sparse_output=False) '.</span>\n",
       "            </div>\n",
       "            \n",
       "            <div class=\"logger-entry\" data-indent=\"0\" style=\"margin-left: 0px;\">\n",
       "                <span class=\"logger-emoji\" style=\"color: #0d6efd;\">‚ú®</span>\n",
       "                <span class=\"logger-message\">Dataset was created successfully!</span>\n",
       "            </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Logger Container */\n",
       "            #logger-container {\n",
       "                max-height: 600px;\n",
       "                overflow-y: auto;\n",
       "                font-family: 'Segoe UI Emoji', 'Segoe UI Symbol', monospace;\n",
       "                padding: 5px;\n",
       "                background-color: #ffffff;\n",
       "                font-size: 0.9em; /* Increased font size */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            /* Individual Log Entry */\n",
       "            .logger-entry {\n",
       "                display: flex;\n",
       "                align-items: center;\n",
       "                padding: 1px 5px;\n",
       "                margin-bottom: 4px;\n",
       "                background-color: #ffffff;\n",
       "                transition: background-color 0.2s, box-shadow 0.2s;\n",
       "                white-space: pre-wrap; /* Preserve whitespace for symbols */\n",
       "                position: relative;\n",
       "            }\n",
       "\n",
       "            .logger-entry:hover {\n",
       "                background-color: #f1f3f5;\n",
       "                box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n",
       "            }\n",
       "\n",
       "        \n",
       "\n",
       "            /* Connector Line styling based on indent */\n",
       "            .logger-entry[data-indent=\"1\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            .logger-entry[data-indent=\"2\"]::before {\n",
       "                left: 0;\n",
       "            }\n",
       "            /* Add more as needed for higher indent levels */\n",
       "\n",
       "            /* Emoji */\n",
       "            .logger-emoji {\n",
       "                margin-right: 10px;\n",
       "                font-size: 1em; /* Larger emoji size */\n",
       "                flex-shrink: 0;\n",
       "                color: inherit; /* Inherit color from parent */\n",
       "            }\n",
       "\n",
       "            /* Message */\n",
       "            .logger-message {\n",
       "                flex-grow: 1;\n",
       "                color: #212529;\n",
       "                word-break: break-word;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_inf = data_collector.collect(n_steps=50, max_steps_per_episode=200, env_seed=None, action_seed=None)\n",
    "\n",
    "dataset_inf = dataset_test = TimeseriesDataset(\n",
    "    df=df_inf,\n",
    "    dataset_config=dataset_config,\n",
    "    train_processors=False,\n",
    "    is_inference=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_planner.plan(dataset_inf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi-optimal-RKvx2dB5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
