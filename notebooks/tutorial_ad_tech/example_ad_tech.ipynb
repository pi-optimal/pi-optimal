{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Ad Delivery with `pi_optimal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The managment of digital advertising campaigns is a complex and dynamic process, and still requires often human work to optimize the delivery of ads to maximize the desired outcome, such as smooth and evenly distributed impression delivery over time. By leveraging **Reinforcement Learning (RL)**, we can optimize the delivery of ads to support or automate human campaign managment. This notebook demonstrates the use of `pi_optimal` to train an RL agent for **ad delivery optimization**, utilizing a dataset of historical ad data, about the campiagns delevery as well as the campaign manager's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "We aim to automate and optimize campaign management for a marketing agency specializing in regional online advertising. Due to the limited geographical scope, achieving smooth and consistent ad delivery over time presents a significant challenge. The agency has provided a dataset of historical ad delivery data. Leveraging `pi_optimal`, our goal is to train a reinforcement learning (RL) agent capable of:\n",
    "\n",
    "- **Delivering ads in a smooth, linear, and efficient manner** throughout the entire campaign duration. \n",
    "\n",
    "This approach seeks to enhance campaign performance, ensure better resource utilization, and improve audience targeting within regional constraints.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset contains 57 adsets which data was collected between the 15th of July 2024 and 13th of November 2024. Every hour a snapshot of the adset state was taken, including the number of impressions delivered by the adset. The dataset also includes the actions taken by the campaign manager to adjust the adset delivery.\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "### Dataset Features\n",
    "\n",
    "1. **AdSet General Information**:\n",
    "    - `created_at`: The date and time where the state and actions of the adset was recorded.\n",
    "    - `unit_index`: The unique identifier of the adset.\n",
    "    - `hour_of_day`: The hour of the day when the adset datapoint was recorded.\n",
    "    - `day_of_week`: The day of the week when the adset datapoint was recorded.\n",
    "    - `adset_name`: The name of the adset.\n",
    "\n",
    "2. **AdSet Delivery Information**:\n",
    "    - `adset_impressions_diff`: The number of impressions delivered in this hour.\n",
    "    - `adset_settings_total_budget`: The total budget of the adset.\n",
    "    - `adset_settings_daily_budget`: The daily budget of the adset.\n",
    "    - `adset_settings_maximum_daily_impressions`: The maximum number of impressions the adset can deliver in a day.\n",
    "    - `adset_settings_maximum_lifetime_impressions`: The maximum number of impressions the adset can deliver in its lifetime.\n",
    "    - `adset_settings_runtime_in_hours`: The total number of hours the adset is going to run.\n",
    "    - `adset_settings_remaining_hours`: The remaining number of hours the adset will run.\n",
    "    - `adset_settings_running_hours`: The number of hours the adset has been running.\n",
    "\n",
    "3. **Campaign Manager Actions**:\n",
    "    - `adset_settings_maximum_cpm`: The maximum CPM set for a specific hour by the campaign manager.\n",
    "    - `adset_targetings_frequency_capping_requests`: The frequency capping requests used by the campaign manager. Frequency capping is a feature that limits the number of times an ad is shown to the same user.\n",
    "    - `adset_settings_bidding_strategy`: The bidding strategy method.\n",
    "    - `adset_settings_pacing_type`: The pacing type of the campaign. Pacing is the rate at which the adset spends its budget.\n",
    "\n",
    "\n",
    "4. **AdSet Delivery Metrics**:\n",
    "    - `total_missing_impressions`: The total number of missing impressions of the total number of impression.\n",
    "    - `expected_impression_next_hour`: The expected number of impressions the adset will deliver in the next hour.\n",
    "    - `hourly_missing_impressions`: The number of missing impressions in this hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>unit_index</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>adset_name</th>\n",
       "      <th>adset_impressions</th>\n",
       "      <th>adset_impressions_diff</th>\n",
       "      <th>adset_settings_total_budget</th>\n",
       "      <th>adset_settings_daily_budget</th>\n",
       "      <th>adset_settings_maximum_daily_impressions</th>\n",
       "      <th>adset_settings_maximum_lifetime_impressions</th>\n",
       "      <th>adset_settings_runtime_in_hours</th>\n",
       "      <th>adset_settings_remaining_hours</th>\n",
       "      <th>adset_settings_running_hours</th>\n",
       "      <th>adset_targetings_total_population</th>\n",
       "      <th>adset_settings_maximum_cpm</th>\n",
       "      <th>adset_targetings_frequency_capping_requests</th>\n",
       "      <th>adset_settings_bidding_strategy</th>\n",
       "      <th>adset_settings_pacing_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-15 14:04:55.531</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>72385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295120</td>\n",
       "      <td>21080</td>\n",
       "      <td>18068.0</td>\n",
       "      <td>252960.0</td>\n",
       "      <td>336</td>\n",
       "      <td>247</td>\n",
       "      <td>88</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-15 14:04:55.531</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Monday</td>\n",
       "      <td>AdBundle</td>\n",
       "      <td>288275.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>272250</td>\n",
       "      <td>19446</td>\n",
       "      <td>72128.0</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>336</td>\n",
       "      <td>247</td>\n",
       "      <td>88</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-15 18:04:51.084</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>AdBundle</td>\n",
       "      <td>288282.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>272250</td>\n",
       "      <td>19446</td>\n",
       "      <td>72128.0</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>336</td>\n",
       "      <td>243</td>\n",
       "      <td>92</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-15 18:04:51.084</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>72385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295120</td>\n",
       "      <td>21080</td>\n",
       "      <td>18068.0</td>\n",
       "      <td>252960.0</td>\n",
       "      <td>336</td>\n",
       "      <td>243</td>\n",
       "      <td>92</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-15 19:05:02.736</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Monday</td>\n",
       "      <td>AdBundle</td>\n",
       "      <td>288282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272250</td>\n",
       "      <td>19446</td>\n",
       "      <td>72128.0</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>336</td>\n",
       "      <td>242</td>\n",
       "      <td>93</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at  unit_index  hour_of_day day_of_week adset_name  \\\n",
       "0 2024-07-15 14:04:55.531           0           14      Monday  Billboard   \n",
       "1 2024-07-15 14:04:55.531           1           14      Monday   AdBundle   \n",
       "2 2024-07-15 18:04:51.084           1           18      Monday   AdBundle   \n",
       "3 2024-07-15 18:04:51.084           0           18      Monday  Billboard   \n",
       "4 2024-07-15 19:05:02.736           1           19      Monday   AdBundle   \n",
       "\n",
       "   adset_impressions  adset_impressions_diff  adset_settings_total_budget  \\\n",
       "0            72385.0                     0.0                       295120   \n",
       "1           288275.0                     7.0                       272250   \n",
       "2           288282.0                     7.0                       272250   \n",
       "3            72385.0                     0.0                       295120   \n",
       "4           288282.0                     0.0                       272250   \n",
       "\n",
       "   adset_settings_daily_budget  adset_settings_maximum_daily_impressions  \\\n",
       "0                        21080                                   18068.0   \n",
       "1                        19446                                   72128.0   \n",
       "2                        19446                                   72128.0   \n",
       "3                        21080                                   18068.0   \n",
       "4                        19446                                   72128.0   \n",
       "\n",
       "   adset_settings_maximum_lifetime_impressions  \\\n",
       "0                                     252960.0   \n",
       "1                                    1009800.0   \n",
       "2                                    1009800.0   \n",
       "3                                     252960.0   \n",
       "4                                    1009800.0   \n",
       "\n",
       "   adset_settings_runtime_in_hours  adset_settings_remaining_hours  \\\n",
       "0                              336                             247   \n",
       "1                              336                             247   \n",
       "2                              336                             243   \n",
       "3                              336                             243   \n",
       "4                              336                             242   \n",
       "\n",
       "   adset_settings_running_hours  adset_targetings_total_population  \\\n",
       "0                            88                          1439387.0   \n",
       "1                            88                          1439387.0   \n",
       "2                            92                          1439387.0   \n",
       "3                            92                          1439387.0   \n",
       "4                            93                          1439387.0   \n",
       "\n",
       "   adset_settings_maximum_cpm  adset_targetings_frequency_capping_requests  \\\n",
       "0                        1190                                         10.0   \n",
       "1                         275                                         10.0   \n",
       "2                         275                                         10.0   \n",
       "3                        1190                                         10.0   \n",
       "4                         275                                         10.0   \n",
       "\n",
       "  adset_settings_bidding_strategy adset_settings_pacing_type  \n",
       "0         IntervalBudgetOptimized                        Off  \n",
       "1         IntervalBudgetOptimized                        Off  \n",
       "2         IntervalBudgetOptimized                        Off  \n",
       "3         IntervalBudgetOptimized                        Off  \n",
       "4         IntervalBudgetOptimized                        Off  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_historical_adset_control = pd.read_csv('data/historical_adset_control.csv', parse_dates=['created_at'])\n",
    "df_historical_adset_control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines for faster training and inference if you have sklearnex installed and are using an Intel CPU\n",
    "\n",
    "#import numpy as np\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the root path to the sys path to load pi_optimal from the parent directory\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Defining the Reward Function\n",
    "\n",
    "The reward function is quite simple and just wants to minimize the hourly missing impressions. The reward function is defined as follows:\n",
    "\n",
    "$\\text{Reward} = - (\\text{Hourly Missing Impressions})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate reward\n",
    "def calculate_reward(row, epsilon=1e-8):\n",
    "\n",
    "    # Calculate the total missing impressions\n",
    "    total_missing_impressions = row.adset_settings_maximum_lifetime_impressions - row.adset_impressions\n",
    "\n",
    "    # Calculate the expected impressions in the next hour (epsilon is added to avoid division by zero)\n",
    "    expected_impression_next_hour = (total_missing_impressions / (row.adset_settings_remaining_hours + epsilon))\n",
    "    expected_impression_next_hour = max(0, expected_impression_next_hour)\n",
    "\n",
    "    # Calculate the hourly missing impressions which prepresents the performance of the current control settings\n",
    "    # when a lot of impressions are missing, the control settings were not optimal\n",
    "    hourly_missing_impressions = ((expected_impression_next_hour - row.adset_impressions_diff) ** 2) ** 0.5\n",
    "\n",
    "    # Total penalty\n",
    "    total_penalty = hourly_missing_impressions\n",
    "\n",
    "    # Reward is the negative of the total penalty\n",
    "    reward = -total_penalty\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the reward function to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>unit_index</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>adset_name</th>\n",
       "      <th>adset_impressions</th>\n",
       "      <th>adset_impressions_diff</th>\n",
       "      <th>adset_settings_total_budget</th>\n",
       "      <th>adset_settings_daily_budget</th>\n",
       "      <th>adset_settings_maximum_daily_impressions</th>\n",
       "      <th>adset_settings_maximum_lifetime_impressions</th>\n",
       "      <th>adset_settings_runtime_in_hours</th>\n",
       "      <th>adset_settings_remaining_hours</th>\n",
       "      <th>adset_settings_running_hours</th>\n",
       "      <th>adset_targetings_total_population</th>\n",
       "      <th>adset_settings_maximum_cpm</th>\n",
       "      <th>adset_targetings_frequency_capping_requests</th>\n",
       "      <th>adset_settings_bidding_strategy</th>\n",
       "      <th>adset_settings_pacing_type</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-15 14:04:55.531</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>72385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295120</td>\n",
       "      <td>21080</td>\n",
       "      <td>18068.0</td>\n",
       "      <td>252960.0</td>\n",
       "      <td>336</td>\n",
       "      <td>247</td>\n",
       "      <td>88</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "      <td>-731.072874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-15 14:04:55.531</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Monday</td>\n",
       "      <td>AdBundle</td>\n",
       "      <td>288275.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>272250</td>\n",
       "      <td>19446</td>\n",
       "      <td>72128.0</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>336</td>\n",
       "      <td>247</td>\n",
       "      <td>88</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "      <td>-2914.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-15 18:04:51.084</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>AdBundle</td>\n",
       "      <td>288282.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>272250</td>\n",
       "      <td>19446</td>\n",
       "      <td>72128.0</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>336</td>\n",
       "      <td>243</td>\n",
       "      <td>92</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "      <td>-2962.209876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-15 18:04:51.084</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Billboard</td>\n",
       "      <td>72385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295120</td>\n",
       "      <td>21080</td>\n",
       "      <td>18068.0</td>\n",
       "      <td>252960.0</td>\n",
       "      <td>336</td>\n",
       "      <td>243</td>\n",
       "      <td>92</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "      <td>-743.106996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-15 19:05:02.736</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Monday</td>\n",
       "      <td>AdBundle</td>\n",
       "      <td>288282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272250</td>\n",
       "      <td>19446</td>\n",
       "      <td>72128.0</td>\n",
       "      <td>1009800.0</td>\n",
       "      <td>336</td>\n",
       "      <td>242</td>\n",
       "      <td>93</td>\n",
       "      <td>1439387.0</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IntervalBudgetOptimized</td>\n",
       "      <td>Off</td>\n",
       "      <td>-2981.479339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at  unit_index  hour_of_day day_of_week adset_name  \\\n",
       "0 2024-07-15 14:04:55.531           0           14      Monday  Billboard   \n",
       "1 2024-07-15 14:04:55.531           1           14      Monday   AdBundle   \n",
       "2 2024-07-15 18:04:51.084           1           18      Monday   AdBundle   \n",
       "3 2024-07-15 18:04:51.084           0           18      Monday  Billboard   \n",
       "4 2024-07-15 19:05:02.736           1           19      Monday   AdBundle   \n",
       "\n",
       "   adset_impressions  adset_impressions_diff  adset_settings_total_budget  \\\n",
       "0            72385.0                     0.0                       295120   \n",
       "1           288275.0                     7.0                       272250   \n",
       "2           288282.0                     7.0                       272250   \n",
       "3            72385.0                     0.0                       295120   \n",
       "4           288282.0                     0.0                       272250   \n",
       "\n",
       "   adset_settings_daily_budget  adset_settings_maximum_daily_impressions  \\\n",
       "0                        21080                                   18068.0   \n",
       "1                        19446                                   72128.0   \n",
       "2                        19446                                   72128.0   \n",
       "3                        21080                                   18068.0   \n",
       "4                        19446                                   72128.0   \n",
       "\n",
       "   adset_settings_maximum_lifetime_impressions  \\\n",
       "0                                     252960.0   \n",
       "1                                    1009800.0   \n",
       "2                                    1009800.0   \n",
       "3                                     252960.0   \n",
       "4                                    1009800.0   \n",
       "\n",
       "   adset_settings_runtime_in_hours  adset_settings_remaining_hours  \\\n",
       "0                              336                             247   \n",
       "1                              336                             247   \n",
       "2                              336                             243   \n",
       "3                              336                             243   \n",
       "4                              336                             242   \n",
       "\n",
       "   adset_settings_running_hours  adset_targetings_total_population  \\\n",
       "0                            88                          1439387.0   \n",
       "1                            88                          1439387.0   \n",
       "2                            92                          1439387.0   \n",
       "3                            92                          1439387.0   \n",
       "4                            93                          1439387.0   \n",
       "\n",
       "   adset_settings_maximum_cpm  adset_targetings_frequency_capping_requests  \\\n",
       "0                        1190                                         10.0   \n",
       "1                         275                                         10.0   \n",
       "2                         275                                         10.0   \n",
       "3                        1190                                         10.0   \n",
       "4                         275                                         10.0   \n",
       "\n",
       "  adset_settings_bidding_strategy adset_settings_pacing_type       reward  \n",
       "0         IntervalBudgetOptimized                        Off  -731.072874  \n",
       "1         IntervalBudgetOptimized                        Off -2914.153846  \n",
       "2         IntervalBudgetOptimized                        Off -2962.209876  \n",
       "3         IntervalBudgetOptimized                        Off  -743.106996  \n",
       "4         IntervalBudgetOptimized                        Off -2981.479339  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the reward calculation\n",
    "df_historical_adset_control['reward'] = df_historical_adset_control.apply(calculate_reward, axis=1)\n",
    "df_historical_adset_control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset Preparation\n",
    "\n",
    "To train a `pi_optimal` RL agent, we must first load and preprocess the ad dataset. The `pi_optimal` package provides a custom dataset class that streamlines the preprocessing pipeline. Below are the key parameters that need to be defined during this process:\n",
    "\n",
    "- **Unit Index**:  \n",
    "   This parameter, `unit_index`, identifies distinct units in the dataset. In our case, each unit corresponds to unique adset (`unit_index` column).\n",
    "\n",
    "- **Time Column**:  \n",
    "   The time column (`timestep_column`) establishes the temporal sequence of data points, enabling the model to learn from historical trends. For instance, the RL agent can consider the previous 24 hours of data (set by the `lookback_timesteps` parameter) to make informed decisions. In our case we would use the datetime column `created_at`.\n",
    "\n",
    "- **Reward Column**:  \n",
    "   The `reward_column` specifies the target that the agent seeks to optimize. Here, we previously calculated and added the `reward` column to the dataset, which reflects just the distance between the current total impressions and the expected current impression given the progression of the campaign.\n",
    "\n",
    "- **State Columns**:  \n",
    "   The state columns capture the system's current status, it includes all variables that influence campaigns delivery performance. Relevant examples include:  \n",
    "   - `adset_targetings_total_population`  \n",
    "   - `adset_settings_total_budget`  \n",
    "   - `day_of_week`  \n",
    "   - ...\n",
    "\n",
    "   These features help the agent assess the current environment and predict outcomes effectively.\n",
    "\n",
    "- **Action Columns**:  \n",
    "   The action columns represent controllable variables, such as the CPM set or the frequency capping settingy. As you can see there are multiple action which we try to optimize at the same time.\n",
    "\n",
    "By carefully defining these parameters, we ensure that the RL agent can interpret the dataset's structure, learn from past patterns, and make optimized decisions to optimize adset delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cols = [\n",
    "    'hour_of_day',\n",
    "    'day_of_week',\n",
    "    'adset_name',\n",
    "    'adset_impressions_diff',\n",
    "    'adset_settings_total_budget',\n",
    "    'adset_settings_daily_budget',\n",
    "    'adset_settings_maximum_daily_impressions',\n",
    "    'adset_settings_maximum_lifetime_impressions',\n",
    "    'adset_settings_runtime_in_hours',\n",
    "    'adset_settings_remaining_hours',\n",
    "    'adset_settings_running_hours',\n",
    "    'adset_targetings_total_population',\n",
    "]\n",
    "\n",
    "action_cols = [\n",
    "    'adset_settings_maximum_cpm',\n",
    "    'adset_targetings_frequency_capping_requests',\n",
    "    'adset_settings_bidding_strategy',\n",
    "    'adset_settings_pacing_type',\n",
    "]\n",
    "\n",
    "reward_col = 'reward'\n",
    "\n",
    "timestamp_col = 'created_at'\n",
    "\n",
    "unit_col = 'unit_index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Beides the columns mentioned above, we could also adjust the number of lookback timesteps for predicting hwo the campaign will evolve in the future. In our case we consider the last 12 hours of data to make a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Converting datetime timesteps to continuous integers\n",
      "WARNING:root:Timesteps between observation don't have a constant duration\n"
     ]
    }
   ],
   "source": [
    "import pi_optimal as po\n",
    "\n",
    "LOOKBACK_TIMESTEPS = 8\n",
    "historical_dataset = po.datasets.timeseries_dataset.TimeseriesDataset(df=df_historical_adset_control,\n",
    "                                                                      state_columns=state_cols,\n",
    "                                                                      action_columns=action_cols,\n",
    "                                                                      reward_column=reward_col,\n",
    "                                                                      timestep_column=timestamp_col,\n",
    "                                                                      unit_index=unit_col,\n",
    "                                                                      lookback_timesteps=LOOKBACK_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Initialization and Training\n",
    "\n",
    "With the dataset prepared, the next crucial step is to initialize and train the Reinforcement Learning (RL) agent. This agent will learn to model the dynamics of the regional online advertising market, enabling it to make informed decisions based on the environment's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:13<00:00,  1.02s/it]\n",
      "100%|██████████| 13/13 [00:20<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from pi_optimal.agents.agent import Agent\n",
    "agent = Agent(dataset=historical_dataset,\n",
    "                 type=\"mpc-continuous\",\n",
    "                 config={\"uncertainty_weight\": 0.5})\n",
    "\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Action Prediction\n",
    "\n",
    "After training the Reinforcement Learning (RL) agent, the next step is to evaluate its performance on new, unseen data. This involves loading data of a running campaign, preparing it using the same preprocessing pipeline as the historical dataset, and then using the trained agent to predict the optimal actions (i.e., adjustments to maxCPM, frequency capping, or bidding strategy) to optmize the delivery objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Current Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current adset control data\n",
    "df_current_adset_control = pd.read_csv('data/current_adset_control.csv', parse_dates=['created_at'])\n",
    "\n",
    "# Apply the reward calculation\n",
    "df_current_adset_control[\"reward\"] = df_current_adset_control.apply(calculate_reward, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Current Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Converting datetime timesteps to continuous integers\n",
      "WARNING:root:Timesteps between observation don't have a constant duration\n"
     ]
    }
   ],
   "source": [
    "current_dataset = po.datasets.timeseries_dataset.TimeseriesDataset(df=df_current_adset_control,\n",
    "                                                                    dataset_config=historical_dataset.dataset_config,\n",
    "                                                                    lookback_timesteps=LOOKBACK_TIMESTEPS,\n",
    "                                                                    train_processors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Optimal Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Top-100 Cost: 0.3519 (Cost: 0.2956, Uncertainty: 0.7044)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2, Top-100 Cost: 0.2299 (Cost: 0.4754, Uncertainty: 0.5246)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3, Top-100 Cost: 0.2313 (Cost: 0.3057, Uncertainty: 0.6943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4, Top-100 Cost: 0.201 (Cost: 0.4351, Uncertainty: 0.5649)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5, Top-100 Cost: 0.2261 (Cost: 0.3305, Uncertainty: 0.6695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6, Top-100 Cost: 0.1969 (Cost: 0.3472, Uncertainty: 0.6528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7, Top-100 Cost: 0.185 (Cost: 0.3889, Uncertainty: 0.6111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8, Top-100 Cost: 0.1915 (Cost: 0.3134, Uncertainty: 0.6866)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9, Top-100 Cost: 0.1889 (Cost: 0.3979, Uncertainty: 0.6021)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Top-100 Cost: 0.1875 (Cost: 0.4907, Uncertainty: 0.5093)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11, Top-100 Cost: 0.1803 (Cost: 0.4048, Uncertainty: 0.5952)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12, Top-100 Cost: 0.1596 (Cost: 0.4002, Uncertainty: 0.5998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13, Top-100 Cost: 0.1771 (Cost: 0.365, Uncertainty: 0.635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14, Top-100 Cost: 0.1751 (Cost: 0.3631, Uncertainty: 0.6369)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15, Top-100 Cost: 0.1764 (Cost: 0.3575, Uncertainty: 0.6425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_actions = agent.predict(current_dataset, inverse_transform=True, n_iter=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Results\n",
    "\n",
    "The agent provides a sequence of optimal actions for the time horizon. Here we print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 0:\n",
      "Maximum CPM: 686.7553139938071\n",
      "Frequency Capping: 1.7964956471576254\n",
      "Bidding Strategy: IntervalBudgetOptimized\n",
      "Pacing Type: EvenlyOverDay\n",
      "\n",
      "--------------------\n",
      "\n",
      "Timestep 1:\n",
      "Maximum CPM: 519.0568100325963\n",
      "Frequency Capping: 1.9338129546496763\n",
      "Bidding Strategy: IntervalBudgetOptimized\n",
      "Pacing Type: EvenlyOverDay\n",
      "\n",
      "--------------------\n",
      "\n",
      "Timestep 2:\n",
      "Maximum CPM: 518.6843900127632\n",
      "Frequency Capping: 3.920755247055057\n",
      "Bidding Strategy: IntervalBudgetOptimized\n",
      "Pacing Type: EvenlyOverDay\n",
      "\n",
      "--------------------\n",
      "\n",
      "Timestep 3:\n",
      "Maximum CPM: 617.5373130999193\n",
      "Frequency Capping: 5.17866268970419\n",
      "Bidding Strategy: IntervalBudgetOptimized\n",
      "Pacing Type: EvenlyOverDay\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_actions)):\n",
    "    print(f\"Timestep {i}:\")\n",
    "    print(\"Maximum CPM:\", best_actions[i][0])\n",
    "    print(\"Frequency Capping:\", best_actions[i][1])\n",
    "    print(\"Bidding Strategy:\", best_actions[i][2])\n",
    "    print(\"Pacing Type:\", best_actions[i][3])\n",
    "    print()\n",
    "    print(\"--------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Step Planning\n",
    "\n",
    "The agent optimizes actions by considering future outcomes over a multi-step horizon. This allows for efficient and forward-thinking decision-making.\n",
    "\n",
    "### Decision-Making Options\n",
    "\n",
    "1. **Full Application of Recommended Actions**: We could choose to apply all recommended actions immediately, for example adjusting maximum cpm, frequency capping, bidding strategy or pacing according to the agent's suggestions for the entire time horizon (e.g., the next 4 hours). Therefore the campaign will be controled based on the agent’s full plan.\n",
    "\n",
    "2. **Incremental Application**: Alternatively, we might apply only the first action in the sequence for the next hour and then the next hour re-run the agent to generate updated recommendations. This method provides flexibility by allowing adjustments based on real-time conditions, while still leveraging the agent’s ability to look multiple steps ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Visualization\n",
    "\n",
    "`pi_optimal` includes a **trajectory visualizer** for the simulated optimal trajectory. This tool allows you to explore the agent's recommendations and analyze their effects on energy consumption and indoor temperature over time. It provides valuable insights into the agent's behavior and helps evaluate its performance across various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pi_optimal.utils.trajectory_visualizer import TrajectoryVisualizer\n",
    "\n",
    "trajectory_visualizer = TrajectoryVisualizer(agent, current_dataset, best_actions=best_actions)\n",
    "trajectory_visualizer.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how `pi_optimal` could be used to optimize ad delivery for regional online advertising campaigns. By training a Reinforcement Learning (RL) agent on historical ad data, we can automate and optimize ad campaigns, ensuring smooth and efficient ad delivery over time. The agent learns to make informed decisions based on the environment's behavior, enabling it to maximize the desired outcome and improve resource utilization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Key Highlights\n",
    "\n",
    "- **Dataset Preparation**: We loaded and preprocessed the ad dataset, defining key parameters such as unit index, time column, reward column, state columns, and action columns.\n",
    "- **Data Type Agnostic Actions**: `pi_optimal` supports a wide range of actions, including continuous, discrete, and multi-dimensional actions. This flexibility allows you to model complex systems and optimize a variety of objectives. Especially in the context of ad tech, where multiple actions can be taken to optimize delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Fine-Tuning the Reward Function**: Experiment with different reward functions to further optimize ad delivery performance. For example, you could consider additional factors such as budget utilization, audience targeting, or campaign reach.\n",
    "\n",
    "2. **Hyperparameter Tuning**: Optimize the agent's hyperparameters to enhance its performance and generalization capabilities. You could explore different neural network architectures, learning rates, or optimization algorithms to improve the agent's learning efficiency.\n",
    "\n",
    "3. **Real-Time Decision-Making**: Extend the agent's capabilities to support real-time decision-making. By integrating the agent with live data streams, you can optimize ad delivery in dynamic and rapidly changing environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- `pi_optimal` Documentation: [GitHub](https://github.com/pi-optimal/pi_optimal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi-optimal-cklzg6dP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
